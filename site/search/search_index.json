{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"JWKNZ Docs In my GitHub Account and this Github Account I have bunch of howto repositories. I might do something more with them one day, but for now they are just code examples. This site serves to provide some documentation for them. To navigate your way through the different tutorials, follow the naviagtion in the left menu. Content All tutorials are written by me and are free for you to learn from. If I use some specific information from a site or person - I will credit them. I use GitHub for my repositories, so I will refer to GitHub by name, but if you use a service like BitBucket or GitLab, just exchange the details where relevant.","title":"JWKNZ Docs"},{"location":"#jwknz_docs","text":"In my GitHub Account and this Github Account I have bunch of howto repositories. I might do something more with them one day, but for now they are just code examples. This site serves to provide some documentation for them. To navigate your way through the different tutorials, follow the naviagtion in the left menu. Content All tutorials are written by me and are free for you to learn from. If I use some specific information from a site or person - I will credit them. I use GitHub for my repositories, so I will refer to GitHub by name, but if you use a service like BitBucket or GitLab, just exchange the details where relevant.","title":"JWKNZ Docs"},{"location":"dotnet_core/","text":"Dotnet Core SQLSVR WEB API","title":"Dotnet Core"},{"location":"dotnet_core/#dotnet_core","text":"SQLSVR WEB API","title":"Dotnet Core"},{"location":"dotnet_core/SQLSVR_WEBAPI/","text":"Introduction This project builds a webapi that is linked to a MSSQL server. It includes the full CRUD operations for the Player table, but the other are empty as part of an exercise. The version for dotnet 2.1.x is here","title":"Introduction"},{"location":"dotnet_core/SQLSVR_WEBAPI/#introduction","text":"This project builds a webapi that is linked to a MSSQL server. It includes the full CRUD operations for the Player table, but the other are empty as part of an exercise. The version for dotnet 2.1.x is here","title":"Introduction"},{"location":"dotnet_core/SQLSVR_WEBAPI/dotnet-2.1.x/01-project-setup/","text":"Project Setup In this project, we are going to look at how to build a webapi that connects to a MSSQL database. The idea (and use case) for this api is to be able to connect any (1 or more) application(s) to a database on a remote or local server without having to store any sensitive information within the application itself. The credentails for the databse will be loaded using environment variables and the system is setup using docker containers, so it is easily deployable. So let's get started! Attention For this tutorial I assume you have the following installed: VSCODE Docker (docker-toolbox or docker for your operating system) You will need to adjust your docker setup or Virtual Box docker VM to support 2GB of RAM to support the MSSQL Server Git (which will give you git bash on Windows) If you do not have docker installed Although the tutorial assumes you use docker, it is only used to run the MSSQL server. If you do not have this option, you will need to do the following: You need to use the Windows operating system Download and install the express edition of MSSQL Server Your username and password will be whatever you set it to be during the setup process. Create a new project How to use the instructions When it says \"Type in\" it means type in the terminal The projectname is a placeholder - type in your own name, but do not type in the angle brackets Not all of these steps are required, but they are useful and they will help you build a good API (and coding habits) - so treat them as if they are all required. If you don't use git Git should be used to manage your code, it is industry standard and in a way the easiest way to manage your code. The alternative is for you to keep copying your work into other folders. I am assuming you use git - so if you don't you will need to find your own work around. Open the Gitbash terminal (from here just reffered to as the terminal) and create your project. Navigate to your code folder, I have mine setup in my users directory - which is where it should be if you are using docker for toolbox, but otherwise anywhere will do. Type in git init webapi to create a working directory with a git repository Go into the folder by typing in cd webapi Type in dotnet --list-sdks to check what versions of dotnet core you have installed on your machine. This is required to see if you need to install the version that this tutorial requires. You should see something like this: Output of dotnet --list-sdks $ dotnet --list-sdks 2.1.505 [/usr/local/share/dotnet/sdk] 2.2.104 [/usr/local/share/dotnet/sdk] 3.0.100-preview-010184 [/usr/local/share/dotnet/sdk] 3.0.100-preview3-010431 [/usr/local/share/dotnet/sdk] Tip You can find all of the dotnet core sdks here But for this tutorial we are working with this version. For this tutorial we are going to focus on version 2.1.x Next type in dotnet new global to create a global.json file that you can use to specify what version of dotnet core you will use for the project. You will need to open this file in a code editor and change the version number to the version you have on your machine - I have 2.1.505 global.json { sdk : { version : 2.1.505 } } Save and close the file. Next create your project by typing in dotnet new webapi -o api --no-https We use the --no-https flag, because we are just going to be running this on our own machine. If you forget this option - the project will still work, but you will get a warning in your browser. Using different versions of the sdk If you create the project before the global.json change, you will create a project with the newest version and some of the instructions below may not work. However if you want to run this project with a later version of dotnet you just need to be aware that you may need to fix up a few minor things later on. Next you will need to create a .gitignore file since we don't want to push all our binary and non essential files into our repository. Open the the .gitignore file from the official dotnet core repository and paste it into your .gitignore file. Back in the terminal start your project by typing in dotnet run and view your site by going to http://localhost:5000/api/values If you see the a json string with: Output of default api [ value1 , value2 ] You now have a working api project and we can start making the changes we need to connect it to a database. Hint for git users Do an initial commit to your repository type in: git add . followed by git commit -m \"Initial Commit\" Making regular commits allows you to revert back to previous version of your code if you make an error. Setting up the database At the moment we have installed the dotnet sdk on our machine and this is the easiest since we can just run the dotnet commands from our terminal. However to run a MSSQL Server you will either need to go through a tedious installation process, if you are on a Windows machine or else up until a year or so ago (end of 2017) you were out of luck. Now Microsoft has embraced the world of containers and it allows us to install it as part of a docker container. So in your terminal (or docker-toolbox for windows git bash terminal) type the following in to download the 2017 version of MSSQL Server docker pull mcr.microsoft.com/mssql/server:2017-latest-ubuntu After the download is complete type in: docker run -e ACCEPT_EULA=Y -e SA_PASSWORD=yourStrong(*)Password -e MSSQL_PID=Express -p 1433:1433 --name webapi_mssql -d mcr.microsoft.com/mssql/server:2017-latest-ubuntu The password is set to yourStrong(*)Password which is the default password with the ! changed into an * - needless to say, you should probably change this, but it would be bad if I document my passwords here Once that you have run that command, you mssql server is up and running, so let's leave that sitting there for the moment. MSSQL checks If you are running the MSSQL database in Docker, your docker setup needs to have at least 2GB of RAM allocated to it. By default Docker Toolbox only allocated 1Gb to the machine. To fix this do this: docker-machine stop // this stops the docker machine Change the amount of ram using the virtualbox GUI interface from 1024MB to 2048GB docker-machine start // this starts the docker machine You can now start the database server by typing in: docker start webapi_mssql Success If all of the stuff above went well, you now have your development environment setup. We will talk about setting up the production side of things later, but let's write some code ... Populating our Database with some data We now need to open our project in our code editor. You should still be in your working directory (webapi) so just type in: # if you are already in your project folder code . This will open the project in Visual Studio Code. Create a folder called sql add 2 files to that folder, call the files tables.sql and data.sql respectively. You can view a set of SQL files in the code repository the table structure can be found here and the data for part of the database can be found here Copy the contents of the files into your project files. Next we need to install an extension so we can execute code, since vscode detected that you are creating sql files, it may have already prompted you to install it. Since we are working with MSSQL it will be the right extension. (Do not install this extension if you are working with MySQL) In any case, if you missed the prompt or it didn't happen, you can type this in the terminal to install it. code --install-extension ms-mssql.mssql After the install is complete, you will need to connect vscode to your database, which you can do like this: vscode-setup-mssql-database-connection.mov Note If you are using docker toolbox, then your docker containers are inside of a Virtualbox VM. Instead of typing in localhost, you will need to type in the VM's ip address, which is: 192.168.99.100 Once you have the connection setup, go to the sql files and right click and select Execute Query Do this for the tables.sql first and then the data.sql You should see the results of the queries pop up in the side pane on the right, which you can close afterwards. Warning The above steps assume your database is still running in the docker container. So if you have any errors, check that first by typing in docker ps -a into the terminal Once you have done these steps, you should run a test query on a table you have just created. Create a new sql file called test.sql can paste this code into it. Use Rugby7db Go SELECT * FROM game_schedule; You can then right-click on it and run the query. You should see a whole lot of data. If you don't something went wrong. SETUP EF Core (Entity Framework) Note This work is done inside of the api project folder, so in your terminal type in cd api so that you can the dotnet commands required. Entity Framework is part of the dotnet family and allows for super easy integration of a database to an application, may it be web based or otherwise. There are 2 approaches you can take: 1) Code First or 2) Data First. Since we already have a database, let's look at the Data First option. Open the api.csproj file inside the api folder and replace the ItemGroup tag with the code below. Note These packages are aligned to work with dotnet core 2.1.x, so these will need to be updated if you are using a newer version. ItemGroup PackageReference Include= Microsoft.AspNetCore.App / PackageReference Include= Microsoft.AspNetCore.Razor.Design Version= 2.1.2 PrivateAssets= All / PackageReference Include= Microsoft.EntityFrameworkCore Version= 2.1.1 / PackageReference Include= Microsoft.EntityFrameworkCore.SqlServer Version= 2.1.1 / PackageReference Include= Microsoft.EntityFrameworkCore.SqlServer.Design Version= 1.1.6 / PackageReference Include= Microsoft.EntityFrameworkCore.Tools Version= 2.1.1 IncludeAssets runtime; build; native; contentfiles; analyzers /IncludeAssets PrivateAssets all /PrivateAssets /PackageReference /ItemGroup Type in dotnet restore to install the nuget packages. Next we need to create models for the tables in the database, so create a folder called Models and then run this command to have it create all the models for you. Note You will need to change the credentials to suit your setup. The DB Context is related to the sql files above, this would obviously be different if you are working on your own project. Using Docker Native dotnet ef dbcontext scaffold Server=localhost;Database=Rugby7db;User=sa;Password=yourStrong(*)Password; Microsoft.EntityFrameworkCore.SqlServer -o Models -f -c Rugby7Context Using Docker Toolbox dotnet ef dbcontext scaffold Server=192.168.99.100;Database=Rugby7db;User=sa;Password=yourStrong(*)Password; Microsoft.EntityFrameworkCore.SqlServer -o Models -f -c Rugby7Context Using SQL EXPRESS dotnet ef dbcontext scaffold Server=myServerAddress;Database=Rugby7db;Trusted_Connection=True; Microsoft.EntityFrameworkCore.SqlServer -o Models -f -c Rugby7Context In your startup.cs file, add the following as your connection string and place it in the ConfigureServices under the services.AddMvc().SetCompatibilityVersion(CompatibilityVersion.Version_2_1); line paste this: Using Docker Native // Connect to DB string connection = Server=localhost;Database=Rugby7db;User=sa;Password=yourStrong(*)Password; ; services.AddDbContext Rugby7Context ( options = options .UseSqlServer ( connection ) ) ; Using Docker Toolbox // Connect to DB string connection = Server=192.168.99.100;Database=Rugby7db;User=sa;Password=yourStrong(*)Password; ; services.AddDbContext Rugby7Context ( options = options .UseSqlServer ( connection ) ) ; Using SQL EXPRESS // Connect to DB string connection = Server=myServerAddress;Database=Rugby7db;Trusted_Connection=True; ; services.AddDbContext Rugby7Context ( options = options .UseSqlServer ( connection ) ) ; Success So now that the database and models are setup, we are able to get to coding the API. We will look at setting up the api controllers in the next section","title":"Project Setup"},{"location":"dotnet_core/SQLSVR_WEBAPI/dotnet-2.1.x/01-project-setup/#project_setup","text":"In this project, we are going to look at how to build a webapi that connects to a MSSQL database. The idea (and use case) for this api is to be able to connect any (1 or more) application(s) to a database on a remote or local server without having to store any sensitive information within the application itself. The credentails for the databse will be loaded using environment variables and the system is setup using docker containers, so it is easily deployable. So let's get started! Attention For this tutorial I assume you have the following installed: VSCODE Docker (docker-toolbox or docker for your operating system) You will need to adjust your docker setup or Virtual Box docker VM to support 2GB of RAM to support the MSSQL Server Git (which will give you git bash on Windows) If you do not have docker installed Although the tutorial assumes you use docker, it is only used to run the MSSQL server. If you do not have this option, you will need to do the following: You need to use the Windows operating system Download and install the express edition of MSSQL Server Your username and password will be whatever you set it to be during the setup process.","title":"Project Setup"},{"location":"dotnet_core/SQLSVR_WEBAPI/dotnet-2.1.x/01-project-setup/#create_a_new_project","text":"How to use the instructions When it says \"Type in\" it means type in the terminal The projectname is a placeholder - type in your own name, but do not type in the angle brackets Not all of these steps are required, but they are useful and they will help you build a good API (and coding habits) - so treat them as if they are all required. If you don't use git Git should be used to manage your code, it is industry standard and in a way the easiest way to manage your code. The alternative is for you to keep copying your work into other folders. I am assuming you use git - so if you don't you will need to find your own work around. Open the Gitbash terminal (from here just reffered to as the terminal) and create your project. Navigate to your code folder, I have mine setup in my users directory - which is where it should be if you are using docker for toolbox, but otherwise anywhere will do. Type in git init webapi to create a working directory with a git repository Go into the folder by typing in cd webapi Type in dotnet --list-sdks to check what versions of dotnet core you have installed on your machine. This is required to see if you need to install the version that this tutorial requires. You should see something like this: Output of dotnet --list-sdks $ dotnet --list-sdks 2.1.505 [/usr/local/share/dotnet/sdk] 2.2.104 [/usr/local/share/dotnet/sdk] 3.0.100-preview-010184 [/usr/local/share/dotnet/sdk] 3.0.100-preview3-010431 [/usr/local/share/dotnet/sdk] Tip You can find all of the dotnet core sdks here But for this tutorial we are working with this version. For this tutorial we are going to focus on version 2.1.x Next type in dotnet new global to create a global.json file that you can use to specify what version of dotnet core you will use for the project. You will need to open this file in a code editor and change the version number to the version you have on your machine - I have 2.1.505 global.json { sdk : { version : 2.1.505 } } Save and close the file. Next create your project by typing in dotnet new webapi -o api --no-https We use the --no-https flag, because we are just going to be running this on our own machine. If you forget this option - the project will still work, but you will get a warning in your browser. Using different versions of the sdk If you create the project before the global.json change, you will create a project with the newest version and some of the instructions below may not work. However if you want to run this project with a later version of dotnet you just need to be aware that you may need to fix up a few minor things later on. Next you will need to create a .gitignore file since we don't want to push all our binary and non essential files into our repository. Open the the .gitignore file from the official dotnet core repository and paste it into your .gitignore file. Back in the terminal start your project by typing in dotnet run and view your site by going to http://localhost:5000/api/values If you see the a json string with: Output of default api [ value1 , value2 ] You now have a working api project and we can start making the changes we need to connect it to a database. Hint for git users Do an initial commit to your repository type in: git add . followed by git commit -m \"Initial Commit\" Making regular commits allows you to revert back to previous version of your code if you make an error.","title":"Create a new project"},{"location":"dotnet_core/SQLSVR_WEBAPI/dotnet-2.1.x/01-project-setup/#setting_up_the_database","text":"At the moment we have installed the dotnet sdk on our machine and this is the easiest since we can just run the dotnet commands from our terminal. However to run a MSSQL Server you will either need to go through a tedious installation process, if you are on a Windows machine or else up until a year or so ago (end of 2017) you were out of luck. Now Microsoft has embraced the world of containers and it allows us to install it as part of a docker container. So in your terminal (or docker-toolbox for windows git bash terminal) type the following in to download the 2017 version of MSSQL Server docker pull mcr.microsoft.com/mssql/server:2017-latest-ubuntu After the download is complete type in: docker run -e ACCEPT_EULA=Y -e SA_PASSWORD=yourStrong(*)Password -e MSSQL_PID=Express -p 1433:1433 --name webapi_mssql -d mcr.microsoft.com/mssql/server:2017-latest-ubuntu The password is set to yourStrong(*)Password which is the default password with the ! changed into an * - needless to say, you should probably change this, but it would be bad if I document my passwords here Once that you have run that command, you mssql server is up and running, so let's leave that sitting there for the moment. MSSQL checks If you are running the MSSQL database in Docker, your docker setup needs to have at least 2GB of RAM allocated to it. By default Docker Toolbox only allocated 1Gb to the machine. To fix this do this: docker-machine stop // this stops the docker machine Change the amount of ram using the virtualbox GUI interface from 1024MB to 2048GB docker-machine start // this starts the docker machine You can now start the database server by typing in: docker start webapi_mssql Success If all of the stuff above went well, you now have your development environment setup. We will talk about setting up the production side of things later, but let's write some code ...","title":"Setting up the database"},{"location":"dotnet_core/SQLSVR_WEBAPI/dotnet-2.1.x/01-project-setup/#populating_our_database_with_some_data","text":"We now need to open our project in our code editor. You should still be in your working directory (webapi) so just type in: # if you are already in your project folder code . This will open the project in Visual Studio Code. Create a folder called sql add 2 files to that folder, call the files tables.sql and data.sql respectively. You can view a set of SQL files in the code repository the table structure can be found here and the data for part of the database can be found here Copy the contents of the files into your project files. Next we need to install an extension so we can execute code, since vscode detected that you are creating sql files, it may have already prompted you to install it. Since we are working with MSSQL it will be the right extension. (Do not install this extension if you are working with MySQL) In any case, if you missed the prompt or it didn't happen, you can type this in the terminal to install it. code --install-extension ms-mssql.mssql After the install is complete, you will need to connect vscode to your database, which you can do like this: vscode-setup-mssql-database-connection.mov Note If you are using docker toolbox, then your docker containers are inside of a Virtualbox VM. Instead of typing in localhost, you will need to type in the VM's ip address, which is: 192.168.99.100 Once you have the connection setup, go to the sql files and right click and select Execute Query Do this for the tables.sql first and then the data.sql You should see the results of the queries pop up in the side pane on the right, which you can close afterwards. Warning The above steps assume your database is still running in the docker container. So if you have any errors, check that first by typing in docker ps -a into the terminal Once you have done these steps, you should run a test query on a table you have just created. Create a new sql file called test.sql can paste this code into it. Use Rugby7db Go SELECT * FROM game_schedule; You can then right-click on it and run the query. You should see a whole lot of data. If you don't something went wrong.","title":"Populating our Database with some data"},{"location":"dotnet_core/SQLSVR_WEBAPI/dotnet-2.1.x/01-project-setup/#setup_ef_core_entity_framework","text":"Note This work is done inside of the api project folder, so in your terminal type in cd api so that you can the dotnet commands required. Entity Framework is part of the dotnet family and allows for super easy integration of a database to an application, may it be web based or otherwise. There are 2 approaches you can take: 1) Code First or 2) Data First. Since we already have a database, let's look at the Data First option. Open the api.csproj file inside the api folder and replace the ItemGroup tag with the code below. Note These packages are aligned to work with dotnet core 2.1.x, so these will need to be updated if you are using a newer version. ItemGroup PackageReference Include= Microsoft.AspNetCore.App / PackageReference Include= Microsoft.AspNetCore.Razor.Design Version= 2.1.2 PrivateAssets= All / PackageReference Include= Microsoft.EntityFrameworkCore Version= 2.1.1 / PackageReference Include= Microsoft.EntityFrameworkCore.SqlServer Version= 2.1.1 / PackageReference Include= Microsoft.EntityFrameworkCore.SqlServer.Design Version= 1.1.6 / PackageReference Include= Microsoft.EntityFrameworkCore.Tools Version= 2.1.1 IncludeAssets runtime; build; native; contentfiles; analyzers /IncludeAssets PrivateAssets all /PrivateAssets /PackageReference /ItemGroup Type in dotnet restore to install the nuget packages. Next we need to create models for the tables in the database, so create a folder called Models and then run this command to have it create all the models for you. Note You will need to change the credentials to suit your setup. The DB Context is related to the sql files above, this would obviously be different if you are working on your own project. Using Docker Native dotnet ef dbcontext scaffold Server=localhost;Database=Rugby7db;User=sa;Password=yourStrong(*)Password; Microsoft.EntityFrameworkCore.SqlServer -o Models -f -c Rugby7Context Using Docker Toolbox dotnet ef dbcontext scaffold Server=192.168.99.100;Database=Rugby7db;User=sa;Password=yourStrong(*)Password; Microsoft.EntityFrameworkCore.SqlServer -o Models -f -c Rugby7Context Using SQL EXPRESS dotnet ef dbcontext scaffold Server=myServerAddress;Database=Rugby7db;Trusted_Connection=True; Microsoft.EntityFrameworkCore.SqlServer -o Models -f -c Rugby7Context In your startup.cs file, add the following as your connection string and place it in the ConfigureServices under the services.AddMvc().SetCompatibilityVersion(CompatibilityVersion.Version_2_1); line paste this: Using Docker Native // Connect to DB string connection = Server=localhost;Database=Rugby7db;User=sa;Password=yourStrong(*)Password; ; services.AddDbContext Rugby7Context ( options = options .UseSqlServer ( connection ) ) ; Using Docker Toolbox // Connect to DB string connection = Server=192.168.99.100;Database=Rugby7db;User=sa;Password=yourStrong(*)Password; ; services.AddDbContext Rugby7Context ( options = options .UseSqlServer ( connection ) ) ; Using SQL EXPRESS // Connect to DB string connection = Server=myServerAddress;Database=Rugby7db;Trusted_Connection=True; ; services.AddDbContext Rugby7Context ( options = options .UseSqlServer ( connection ) ) ; Success So now that the database and models are setup, we are able to get to coding the API. We will look at setting up the api controllers in the next section","title":"SETUP EF Core (Entity Framework)"},{"location":"dotnet_core/SQLSVR_WEBAPI/dotnet-2.1.x/02-create-api/","text":"Creating an API In this part we are going to create a CRUD api that is connected MSSQL. This part will dive right into creating the api controller. So if you need to setup the project,read part 1 first. The Models When looking at creating an API, the design pattern closely follows the one of an MVC paradigm - but it doesn't include the V (View). We still need to use controllers and we still need to use models , but we have already created those in part 1. The main part to point out is that Models are normal POCO (plain old class objects) files, but only include properties - there are no methods, fields, constructors etc. of any kind in these files. DBContext When creating your models using Entity Framework you also create a DBContext, in this demo we created one called Rugby7Context. In this file we have a method that creates our models, it reads the structure of our SQL tables and then using a ModelBuilder it creates our model classes, which contain all of our column names and their properties. Warning If you need to make a change to your table, you can do so, but you also need to rerun the ef scafholding command. These would be the steps to take: Make changes to your SQL file Recreate the table structure Run the EF Scafholding command (in part 1) The Controller The Controllers are the beasts in the api, they can be big complex files depending on the table structure you have in your database. Before you start Delete the controller that is already in the Controllers folder called ValuesController.cs We will create new controller files and if you overwrite this one, it may cause some unneccesary confusion. Let's break down a few basics: The Controller Name Each Controller matches a single model - no more no less. Each Model is linked to a single table in the SQL database - no more no less. Each Controller inherites from the ControllerBase class, where the different Route routes are defined. To make sure that each Controller knows it is specific for a web api, we need to add some attributes to the class and its methods. Just above the class we need these 2 attrinbutes API Attribute Definition [ApiController] This indicates that we are creating an API [Route(\"api/[controller]\")] Sits above the ApiController and defines the route we need to view our data Inside the class above each of the routing methods, we need to place these. API Attribute Definition [HttpGet] Used for a Get method, returns all the data in the api for this controller [HttpGet](\"{id}\") Same as an HttpGet attribute, but only returns the data for a specific id, which corrolates to a row of the table in the database. [HttpPost] Add data to our database, this takes an instance of the model as a parameter. [HttpPut(\"{id}\")] Update an existing item in the database, this takes 2 parameters - 1 for the id that needs to be updated and 2 an instance of the model to process the properties. [HttpDelete(\"{id}\")] Removes the item with the selected id, so that will need to be passed in as the parameter to the method. Next up we need instantiate the model context that matches the controller: Setting up the context private readonly Name - of - Context _context ; public Name - of - Controller ( Name - of - Context context ) { _context = context ; } In the code above, the Context and Controller are matching the code given with the sql file - again if you are using different data then your project then you will need to change that. The only other thing that the controller contains are the routing methods - anything not related to the routing is not included in this class. Any helper methods should be included in a seperate class to keep things clean. Creating a controller In Visual Studio (the big IDE) controllers are easy to create, by right clicking on your project and click add new file . You then select that you want to add a Controller and name it accordingly. In Visual Studio Code the process is a bit more manual, but not difficult. Inside the controller folder create a file name it as the controller you want to create: NameController.cs for example PlayersController.cs Next add the following code inside this file: using System ; using System.Collections.Generic ; using System.Linq ; using System.Threading.Tasks ; using Microsoft.AspNetCore.Mvc ; using Microsoft.EntityFrameworkCore ; using api.Models ; namespace api.Controllers { [Route( api/[controller] )] [ApiController] public class NameController : ControllerBase { [HttpGet] public async Task ActionResult IEnumerable MODEL GetMODEL () { return await _context . MODEL . ToListAsync (); } [HttpGet( {id} )] public async Task ActionResult MODEL GetMODEL ( long id ) { MODEL item = await _context . MODEL . FindAsync ( id ); if ( item == null ) { return NotFound (); } return item ; } [HttpPost] public async Task ActionResult MODEL PostMODEL ( MODEL item ) { _context . MODEL . Add ( item ); await _context . SaveChangesAsync (); return CreatedAtAction ( nameof ( GetMODEL ), item ); } [HttpPut( {id} )] public async Task IActionResult PutMODELItem ( short id , MODEL item ) { if ( id != item . id ) { return BadRequest (); } _context . Entry ( item ). State = EntityState . Modified ; await _context . SaveChangesAsync (); return Content ( MODEL has been updated ); } [HttpDelete( {id} )] public async Task IActionResult DeleteMODELItem ( short id ) { MODEL model = await _context . MODEL . FindAsync ( id ); if ( model == null ) { return NotFound (); } _context . MODEL . Remove ( model ); await _context . SaveChangesAsync (); return Content ( Model has been removed ); } } } Where ever it says Model in the code above, replace it with the name of the model that this controller matches. You will also need to resolve all the namespaces and import any that are required to run the controller. Don't worry - Visual Studio is very good at pointing them out to you Let's have a look what each of the methods mean in more detail. The HttpGet Method Demo Code [HttpGet] public async Task ActionResult IEnumerable MODEL GetMODEL () { return await _context . MODEL . ToListAsync (); } The HttpGet is the simplest of all, you define that you want a method that returns IEnumerable ModelName and call it give it a meaningful name like: GetModels() You then just return the context with the model class convert it to a List The Single ID HttpGet Method Demo Code [HttpGet( {id} )] public async Task ActionResult MODEL GetMODEL ( long id ) { MODEL item = await _context . MODEL . FindAsync ( id ); if ( item == null ) { return NotFound (); } return item ; } First we need to see if the id is in the database and if it isn't we need to return that message to the api user. If it does exist then return that object to the api user. Since we are only returning a single instance, we don't need to return it as a list. HttpPost Method Demo Code [HttpPost] public async Task ActionResult MODEL PostMODEL ( MODEL item ) { _context . MODEL . Add ( item ); await _context . SaveChangesAsync (); return CreatedAtAction ( nameof ( GetMODEL ), item ); } We can only ever add a single object to the database The item gets added and is saved to the databse The object details are returned to the api user HttpPut Method Demo Code [HttpPut( {id} )] public async Task IActionResult PutMODELItem ,( short id , MODEL item ) { if ( id != item . id ) { return BadRequest (); } _context . Entry ( item ). State = EntityState . Modified ; await _context . SaveChangesAsync (); return Content ( MODEL has been updated ); } First we check if the id argument exists in the database and if it doesn't the request is cancelled. If the id does exists the EntitySate uses the Modified property to flag any changes The data is then updated and saved We return a message to the API user Warning There are a couple of things to watch out for when updating data: If your SQL code does not have an id columnn called id, then you will need to pass in the id property in your data You will need to pass in the id you want to update in the URL, otherwise it will update all of the data that HttpDelete Method Demo Code [HttpDelete( {id} )] public async Task IActionResult DeleteMODELItem ( short id ) { MODEL model = await _context . MODEL . FindAsync ( id ); if ( model == null ) { return NotFound (); } _context . MODEL . Remove ( model ); await _context . SaveChangesAsync (); return Content ( Model has been removed ); } The first part is the same as what you have seen in the HttpGet(\"{id}\") method. If the record is found, it is removed The api user gets a message General Notes: So that is all you need to do to create a simple api and because we use the entity framework, the context does all the heavy lifting for you. Even so - there a couple of things to note: the Get Methods, return data from the database, this will be returned to the api user in JSON format by default. the Post, Put and Delete method don't return anything by default, but you still need to inform the api user. For this we can use the Content() that takes string. It would be nice to return a string that is formatted in JSON format, so use something like \"{msg: user has been updated}\" REMEMBER TO CHANGE ALL THE REFERENCES TO THE WORD \"MODEL\" TO THE ACTUAL MODEL YOU ARE MAKING THE CONTOLLER FOR Next let's do some exercises!","title":"Creating an API"},{"location":"dotnet_core/SQLSVR_WEBAPI/dotnet-2.1.x/02-create-api/#creating_an_api","text":"In this part we are going to create a CRUD api that is connected MSSQL. This part will dive right into creating the api controller. So if you need to setup the project,read part 1 first.","title":"Creating an API"},{"location":"dotnet_core/SQLSVR_WEBAPI/dotnet-2.1.x/02-create-api/#the_models","text":"When looking at creating an API, the design pattern closely follows the one of an MVC paradigm - but it doesn't include the V (View). We still need to use controllers and we still need to use models , but we have already created those in part 1. The main part to point out is that Models are normal POCO (plain old class objects) files, but only include properties - there are no methods, fields, constructors etc. of any kind in these files.","title":"The Models"},{"location":"dotnet_core/SQLSVR_WEBAPI/dotnet-2.1.x/02-create-api/#dbcontext","text":"When creating your models using Entity Framework you also create a DBContext, in this demo we created one called Rugby7Context. In this file we have a method that creates our models, it reads the structure of our SQL tables and then using a ModelBuilder it creates our model classes, which contain all of our column names and their properties. Warning If you need to make a change to your table, you can do so, but you also need to rerun the ef scafholding command. These would be the steps to take: Make changes to your SQL file Recreate the table structure Run the EF Scafholding command (in part 1)","title":"DBContext"},{"location":"dotnet_core/SQLSVR_WEBAPI/dotnet-2.1.x/02-create-api/#the_controller","text":"The Controllers are the beasts in the api, they can be big complex files depending on the table structure you have in your database. Before you start Delete the controller that is already in the Controllers folder called ValuesController.cs We will create new controller files and if you overwrite this one, it may cause some unneccesary confusion. Let's break down a few basics:","title":"The Controller"},{"location":"dotnet_core/SQLSVR_WEBAPI/dotnet-2.1.x/02-create-api/#the_controller_name","text":"Each Controller matches a single model - no more no less. Each Model is linked to a single table in the SQL database - no more no less. Each Controller inherites from the ControllerBase class, where the different Route routes are defined. To make sure that each Controller knows it is specific for a web api, we need to add some attributes to the class and its methods. Just above the class we need these 2 attrinbutes API Attribute Definition [ApiController] This indicates that we are creating an API [Route(\"api/[controller]\")] Sits above the ApiController and defines the route we need to view our data Inside the class above each of the routing methods, we need to place these. API Attribute Definition [HttpGet] Used for a Get method, returns all the data in the api for this controller [HttpGet](\"{id}\") Same as an HttpGet attribute, but only returns the data for a specific id, which corrolates to a row of the table in the database. [HttpPost] Add data to our database, this takes an instance of the model as a parameter. [HttpPut(\"{id}\")] Update an existing item in the database, this takes 2 parameters - 1 for the id that needs to be updated and 2 an instance of the model to process the properties. [HttpDelete(\"{id}\")] Removes the item with the selected id, so that will need to be passed in as the parameter to the method. Next up we need instantiate the model context that matches the controller: Setting up the context private readonly Name - of - Context _context ; public Name - of - Controller ( Name - of - Context context ) { _context = context ; } In the code above, the Context and Controller are matching the code given with the sql file - again if you are using different data then your project then you will need to change that. The only other thing that the controller contains are the routing methods - anything not related to the routing is not included in this class. Any helper methods should be included in a seperate class to keep things clean.","title":"The Controller Name"},{"location":"dotnet_core/SQLSVR_WEBAPI/dotnet-2.1.x/02-create-api/#creating_a_controller","text":"In Visual Studio (the big IDE) controllers are easy to create, by right clicking on your project and click add new file . You then select that you want to add a Controller and name it accordingly. In Visual Studio Code the process is a bit more manual, but not difficult. Inside the controller folder create a file name it as the controller you want to create: NameController.cs for example PlayersController.cs Next add the following code inside this file: using System ; using System.Collections.Generic ; using System.Linq ; using System.Threading.Tasks ; using Microsoft.AspNetCore.Mvc ; using Microsoft.EntityFrameworkCore ; using api.Models ; namespace api.Controllers { [Route( api/[controller] )] [ApiController] public class NameController : ControllerBase { [HttpGet] public async Task ActionResult IEnumerable MODEL GetMODEL () { return await _context . MODEL . ToListAsync (); } [HttpGet( {id} )] public async Task ActionResult MODEL GetMODEL ( long id ) { MODEL item = await _context . MODEL . FindAsync ( id ); if ( item == null ) { return NotFound (); } return item ; } [HttpPost] public async Task ActionResult MODEL PostMODEL ( MODEL item ) { _context . MODEL . Add ( item ); await _context . SaveChangesAsync (); return CreatedAtAction ( nameof ( GetMODEL ), item ); } [HttpPut( {id} )] public async Task IActionResult PutMODELItem ( short id , MODEL item ) { if ( id != item . id ) { return BadRequest (); } _context . Entry ( item ). State = EntityState . Modified ; await _context . SaveChangesAsync (); return Content ( MODEL has been updated ); } [HttpDelete( {id} )] public async Task IActionResult DeleteMODELItem ( short id ) { MODEL model = await _context . MODEL . FindAsync ( id ); if ( model == null ) { return NotFound (); } _context . MODEL . Remove ( model ); await _context . SaveChangesAsync (); return Content ( Model has been removed ); } } } Where ever it says Model in the code above, replace it with the name of the model that this controller matches. You will also need to resolve all the namespaces and import any that are required to run the controller. Don't worry - Visual Studio is very good at pointing them out to you Let's have a look what each of the methods mean in more detail.","title":"Creating a controller"},{"location":"dotnet_core/SQLSVR_WEBAPI/dotnet-2.1.x/02-create-api/#the_httpget_method","text":"Demo Code [HttpGet] public async Task ActionResult IEnumerable MODEL GetMODEL () { return await _context . MODEL . ToListAsync (); } The HttpGet is the simplest of all, you define that you want a method that returns IEnumerable ModelName and call it give it a meaningful name like: GetModels() You then just return the context with the model class convert it to a List","title":"The HttpGet Method"},{"location":"dotnet_core/SQLSVR_WEBAPI/dotnet-2.1.x/02-create-api/#the_single_id_httpget_method","text":"Demo Code [HttpGet( {id} )] public async Task ActionResult MODEL GetMODEL ( long id ) { MODEL item = await _context . MODEL . FindAsync ( id ); if ( item == null ) { return NotFound (); } return item ; } First we need to see if the id is in the database and if it isn't we need to return that message to the api user. If it does exist then return that object to the api user. Since we are only returning a single instance, we don't need to return it as a list.","title":"The Single ID HttpGet Method"},{"location":"dotnet_core/SQLSVR_WEBAPI/dotnet-2.1.x/02-create-api/#httppost_method","text":"Demo Code [HttpPost] public async Task ActionResult MODEL PostMODEL ( MODEL item ) { _context . MODEL . Add ( item ); await _context . SaveChangesAsync (); return CreatedAtAction ( nameof ( GetMODEL ), item ); } We can only ever add a single object to the database The item gets added and is saved to the databse The object details are returned to the api user","title":"HttpPost Method"},{"location":"dotnet_core/SQLSVR_WEBAPI/dotnet-2.1.x/02-create-api/#httpput_method","text":"Demo Code [HttpPut( {id} )] public async Task IActionResult PutMODELItem ,( short id , MODEL item ) { if ( id != item . id ) { return BadRequest (); } _context . Entry ( item ). State = EntityState . Modified ; await _context . SaveChangesAsync (); return Content ( MODEL has been updated ); } First we check if the id argument exists in the database and if it doesn't the request is cancelled. If the id does exists the EntitySate uses the Modified property to flag any changes The data is then updated and saved We return a message to the API user Warning There are a couple of things to watch out for when updating data: If your SQL code does not have an id columnn called id, then you will need to pass in the id property in your data You will need to pass in the id you want to update in the URL, otherwise it will update all of the data that","title":"HttpPut Method"},{"location":"dotnet_core/SQLSVR_WEBAPI/dotnet-2.1.x/02-create-api/#httpdelete_method","text":"Demo Code [HttpDelete( {id} )] public async Task IActionResult DeleteMODELItem ( short id ) { MODEL model = await _context . MODEL . FindAsync ( id ); if ( model == null ) { return NotFound (); } _context . MODEL . Remove ( model ); await _context . SaveChangesAsync (); return Content ( Model has been removed ); } The first part is the same as what you have seen in the HttpGet(\"{id}\") method. If the record is found, it is removed The api user gets a message","title":"HttpDelete Method"},{"location":"dotnet_core/SQLSVR_WEBAPI/dotnet-2.1.x/02-create-api/#general_notes","text":"So that is all you need to do to create a simple api and because we use the entity framework, the context does all the heavy lifting for you. Even so - there a couple of things to note: the Get Methods, return data from the database, this will be returned to the api user in JSON format by default. the Post, Put and Delete method don't return anything by default, but you still need to inform the api user. For this we can use the Content() that takes string. It would be nice to return a string that is formatted in JSON format, so use something like \"{msg: user has been updated}\" REMEMBER TO CHANGE ALL THE REFERENCES TO THE WORD \"MODEL\" TO THE ACTUAL MODEL YOU ARE MAKING THE CONTOLLER FOR Next let's do some exercises!","title":"General Notes:"},{"location":"dotnet_core/SQLSVR_WEBAPI/dotnet-2.1.x/03-exercise-01/","text":"Exercises Exercise 1 The database has a number of tables in it and Entity Framework created the Models for us. Now create the controllers for each of the following Models. Model Name Controller Name GameSchedule GameScheduleController Players PlayersController PoolPoints PoolPointsController Staff StaffController Teams TeamsController Your task is to complete the api so data can be submitted using PostMan and a Visual Studio Code plugin incase you can't use postman. We will look at testing our API next","title":"Exercises"},{"location":"dotnet_core/SQLSVR_WEBAPI/dotnet-2.1.x/03-exercise-01/#exercises","text":"","title":"Exercises"},{"location":"dotnet_core/SQLSVR_WEBAPI/dotnet-2.1.x/03-exercise-01/#exercise_1","text":"The database has a number of tables in it and Entity Framework created the Models for us. Now create the controllers for each of the following Models. Model Name Controller Name GameSchedule GameScheduleController Players PlayersController PoolPoints PoolPointsController Staff StaffController Teams TeamsController Your task is to complete the api so data can be submitted using PostMan and a Visual Studio Code plugin incase you can't use postman. We will look at testing our API next","title":"Exercise 1"},{"location":"dotnet_core/SQLSVR_WEBAPI/dotnet-2.1.x/04-testing-the-api/","text":"Testing the api using VSCODE Now that we have created our API and all the controllers for it, we need to test it - and then fix anything that went wrong There are a number of tools that you can use to test an API. A popular one being Postman (this is a free tool). However you do need to install the program, so you can also keep everything inside of Visual Studio Code. First let's have a look at using a Visual Studio Code Extension, since it allows us to save the routes we want to test. REST Client Install the following extension: code --install-extension humao.rest-client We need to have a file that ends with an http extension to test our routes, but to keep our folder structure tidy we will put them in a folder. Create a folder called test-routes and inside of that folder create the following files: get-routes.http post-routes.http put-routes.http delete-routes.http GET ROUTE Open the get-routes.http file and add the following code: #GET http://localhost:5000/api/gameschedule/ #GET http://localhost:5000/api/gameschedule/f2 #GET http://localhost:5000/api/players/ #GET http://localhost:5000/api/poolpoints/ #GET http://localhost:5000/api/poolpoints/1 #GET http://localhost:5000/api/staff/ #GET http://localhost:5000/api/staff/1 #GET http://localhost:5000/api/teams/ #GET http://localhost:5000/api/teams/AKLF You can only test a single request at a time, so uncomment each request to see the result. Get Successful HTTP/1.1 200 OK Connection: close Date: Tue, 07 May 2019 03:30:27 GMT Content-Type: application/json; charset=utf-8 Server: Kestrel Transfer-Encoding: chunked { id : f2 , fieldNumber : 2, time : 10.25am , teamA : BOPF , teamB : HAWF , teamAScore : null, teamBScore : null } Now if you receive any errors, make sure you have got the right setup in each controller. Copy and pasting code You may have copied the controller file a number of times and resolvded all the dependencies and your code would have compiled, but have you checked your models against your controllers?? Copy and pasting code without checking it - may compile your code - may not be correct at run time. POST ROUTE For the post route, we need to supply some data that would otherwise come through a form. So the request file will look a little different: # POST http://localhost:5000/api/players # content-type: application/json # { # Name : Stephen Holland , # TeamId : AKLM , # } ################################################ # POST http://localhost:5000/api/players # content-type: application/json # { # Name : Lisa England , # TeamId : AKLF , # } You will we still target the URL, but we use the word POST. We also need to specify the content type, since we are sending JSON data. Inside of the curly braces, we place the content that matches the Model in our code. When the Post is successful you will see a message like: Post Successfull HTTP/1.1 201 Created Connection: close Date: Tue, 07 May 2019 03:27:24 GMT Content-Type: application/json; charset=utf-8 Server: Kestrel Transfer-Encoding: chunked Location: http://localhost:5000/api/Players { id : 2, name : Lisa England , teamId : AKLF } PUT ROUTE For the update route, we need to have the ID of the record we want to change and the new data, so those requests look like: PUT http://localhost:5000/api/players/1 content-type: application/json { id : 1, Name : Lisa England , TeamId : HWBF , } The result of the request looks like this: Update Successful HTTP/1.1 200 OK Connection: close Date: Tue, 07 May 2019 03:33:00 GMT Content-Type: text/plain; charset=utf-8 Server: Kestrel Content-Length: 24 Players has been updated Note that we need the ID as part of the URL, but also in the request block?? This is because if we where to use a webform, the id is grabbed from the URL and placed in the request behind the scenes. DELETE ROUTE For the delete request, we only need the ID - so that is simple DELETE http://localhost:5000/api/players/1 content-type: application/json A successul request would look like: Update Successful HTTP/1.1 200 OK Connection: close Date: Tue, 07 May 2019 03:35:35 GMT Content-Type: text/plain; charset=utf-8 Server: Kestrel Content-Length: 22 Player has been removed All done! Since we ran the tests inside of VSCODE, we have them saved - so it is easy to use them again.","title":"Testing the api using VSCODE"},{"location":"dotnet_core/SQLSVR_WEBAPI/dotnet-2.1.x/04-testing-the-api/#testing_the_api_using_vscode","text":"Now that we have created our API and all the controllers for it, we need to test it - and then fix anything that went wrong There are a number of tools that you can use to test an API. A popular one being Postman (this is a free tool). However you do need to install the program, so you can also keep everything inside of Visual Studio Code. First let's have a look at using a Visual Studio Code Extension, since it allows us to save the routes we want to test.","title":"Testing the api using VSCODE"},{"location":"dotnet_core/SQLSVR_WEBAPI/dotnet-2.1.x/04-testing-the-api/#rest_client","text":"Install the following extension: code --install-extension humao.rest-client We need to have a file that ends with an http extension to test our routes, but to keep our folder structure tidy we will put them in a folder. Create a folder called test-routes and inside of that folder create the following files: get-routes.http post-routes.http put-routes.http delete-routes.http","title":"REST Client"},{"location":"dotnet_core/SQLSVR_WEBAPI/dotnet-2.1.x/04-testing-the-api/#get_route","text":"Open the get-routes.http file and add the following code: #GET http://localhost:5000/api/gameschedule/ #GET http://localhost:5000/api/gameschedule/f2 #GET http://localhost:5000/api/players/ #GET http://localhost:5000/api/poolpoints/ #GET http://localhost:5000/api/poolpoints/1 #GET http://localhost:5000/api/staff/ #GET http://localhost:5000/api/staff/1 #GET http://localhost:5000/api/teams/ #GET http://localhost:5000/api/teams/AKLF You can only test a single request at a time, so uncomment each request to see the result. Get Successful HTTP/1.1 200 OK Connection: close Date: Tue, 07 May 2019 03:30:27 GMT Content-Type: application/json; charset=utf-8 Server: Kestrel Transfer-Encoding: chunked { id : f2 , fieldNumber : 2, time : 10.25am , teamA : BOPF , teamB : HAWF , teamAScore : null, teamBScore : null } Now if you receive any errors, make sure you have got the right setup in each controller. Copy and pasting code You may have copied the controller file a number of times and resolvded all the dependencies and your code would have compiled, but have you checked your models against your controllers?? Copy and pasting code without checking it - may compile your code - may not be correct at run time.","title":"GET ROUTE"},{"location":"dotnet_core/SQLSVR_WEBAPI/dotnet-2.1.x/04-testing-the-api/#post_route","text":"For the post route, we need to supply some data that would otherwise come through a form. So the request file will look a little different: # POST http://localhost:5000/api/players # content-type: application/json # { # Name : Stephen Holland , # TeamId : AKLM , # } ################################################ # POST http://localhost:5000/api/players # content-type: application/json # { # Name : Lisa England , # TeamId : AKLF , # } You will we still target the URL, but we use the word POST. We also need to specify the content type, since we are sending JSON data. Inside of the curly braces, we place the content that matches the Model in our code. When the Post is successful you will see a message like: Post Successfull HTTP/1.1 201 Created Connection: close Date: Tue, 07 May 2019 03:27:24 GMT Content-Type: application/json; charset=utf-8 Server: Kestrel Transfer-Encoding: chunked Location: http://localhost:5000/api/Players { id : 2, name : Lisa England , teamId : AKLF }","title":"POST ROUTE"},{"location":"dotnet_core/SQLSVR_WEBAPI/dotnet-2.1.x/04-testing-the-api/#put_route","text":"For the update route, we need to have the ID of the record we want to change and the new data, so those requests look like: PUT http://localhost:5000/api/players/1 content-type: application/json { id : 1, Name : Lisa England , TeamId : HWBF , } The result of the request looks like this: Update Successful HTTP/1.1 200 OK Connection: close Date: Tue, 07 May 2019 03:33:00 GMT Content-Type: text/plain; charset=utf-8 Server: Kestrel Content-Length: 24 Players has been updated Note that we need the ID as part of the URL, but also in the request block?? This is because if we where to use a webform, the id is grabbed from the URL and placed in the request behind the scenes.","title":"PUT ROUTE"},{"location":"dotnet_core/SQLSVR_WEBAPI/dotnet-2.1.x/04-testing-the-api/#delete_route","text":"For the delete request, we only need the ID - so that is simple DELETE http://localhost:5000/api/players/1 content-type: application/json A successul request would look like: Update Successful HTTP/1.1 200 OK Connection: close Date: Tue, 07 May 2019 03:35:35 GMT Content-Type: text/plain; charset=utf-8 Server: Kestrel Content-Length: 22 Player has been removed All done! Since we ran the tests inside of VSCODE, we have them saved - so it is easy to use them again.","title":"DELETE ROUTE"},{"location":"dotnet_core/SQLSVR_WEBAPI/dotnet-2.1.x/05-adding-a-web-form/","text":"Consuming the API Now that the api is working, we need to be able to interact with it. A normal user isn't going to use postman - they don't even want to know they are using an API. Setting up the project The purpose of the api is deliver content in such a way that it can be consumed by 1 or more applications. This is why an api should be setup in its own project. For that reason we are now going to create a new project that consumes our api. At the moment we have the following structure: root |--.vscode/ |--api/ |--sql/ |--global.json |--.git/ # you may not see this folder, but it is there if you use git |--.gitignore For this project to work we are going to expand it to the following folder structure: root |--.vscode/ |--api/ |--web/ |--sql/ |--global.json |--.git/ # you may not see this folder, but it is there if you use git |--.gitignore Separating the project This project is still maintained in a single repository. The main focus is still the api, the web component is a means to make sure people can see an implementation of it. For this part you will need to be in the webapi folder, so you have to type in cd .. in the terminal. The prompt should now say webapi . In the api folder we have the actual api, this was created using the dotnet new webapi -o api command. For the web project we are going to use the following command: dotnet new webapp -o web --no-https We are able to use frameworks like react (these templates are offered by dotnet), but let's focus on interacting with the api. Let's also make sure our api is running: dotnet run -p api Since our terminal is now taken up by the application, we need to open another one. Just click the + symbol at the top of the terminal, if you are using the integrated terminal - this will create another terminal instance. Changing some settings in the web project Next we need to change the port on which the web project runs, since the api takes up port 5000. In the launchsettings.json file, change the port on line 21 from 5000 to 6000 . If you didn't use the --no-https flag when creating the project, you will also need to change 5001 into 6001 for the https port. Run the project by using dotnet run and you will see that you now have 2 dotnet services running. You can now see your project on https://localhost:6001 or http://localhost:6000 Cleaning up the project The webapp template comes with a lot of boilerplate code that we don't need, so let's remove and change some files: Remove the following files in the Pages folder: About.cshtml About.cshtml.cs Contact.cshtml Contact.cshtml.cs Error.cshtml Error.cshtml.cs Privacy.cshtml Privacy.cshtml.cs Index.cshtml file @page @model IndexModel @{ ViewData[ Title ] = API Page ; ViewData[ ApiType ] = Player Data ; } h1 @ViewData[ Title ] /h1 h2 @ViewData[ ApiType ] /h2 div id= data ul /ul /div Change the Pages/Shared/_Layout.cshtml file into this: _Layout.cshtml file !DOCTYPE html html head meta charset= utf-8 / meta name= viewport content= width=device-width, initial-scale=1.0 / title @ViewData[ Title ] - web /title link rel= stylesheet href= ~/lib/bootstrap/dist/css/bootstrap.css / link rel= stylesheet href= ~/css/site.css / /head body nav class= navbar navbar-inverse navbar-fixed-top div class= container div class= navbar-header button type= button class= navbar-toggle data-toggle= collapse data-target= .navbar-collapse span class= sr-only Toggle navigation /span span class= icon-bar /span span class= icon-bar /span span class= icon-bar /span /button a asp-page= /Index class= navbar-brand web /a /div div class= navbar-collapse collapse ul class= nav navbar-nav li a asp-page= /Index Home /a /li /ul /div /div /nav div class= container body-content @RenderBody() hr / footer p copy; 2019 - web /p /footer /div @RenderSection( Scripts , required: false) /body /html You may notice a few odd symbols - we look at them later, so don't worry about them for now. Project Setup In the wwwroot folder is all of our static and public accessible stuff like images, css and javascript files. We won't really touch them, but that is where they are if you need to find them. In the Pages folder are all the dynamic files. The .cshtml.cs files are the View - the things we see in the web browser. the .cs file with the same name is the code-behind for that page. These pages are reffered to as Razor pages. Razor pages still use the Model View Controller Setup, but it is a bit easier to manage them. First API Call Let's get something from our API on the page. To get something on the page we need to make an api call and that api call is going to return to us a JSON string. So getting remote data onto our website from an api is done using Javascript - No C# involved here (but we will add some later on). Add this simple fetch request to your Index.cshtml page inside a set script tags. fetch ( https://localhost:5001/api/players ) . then ( res = res . json ()) . then ( data = { let players = data . map ( d = ` li ${ d . name } /li ` ) document . querySelector ( #data ul ). innerHTML = players }) You will get a CORS (Cross-Origin Resource Sharing) error, since your api and web page are on a different URL. Back in the API project, you will need to enable CORS and for now, we are just going allow it. You will need to tighten up the security when you are in the production stage of your code. Allowing CORS is easy and it is all done in your Startup.cs file. In the public void Configure method add the following middleware: app.UseCors(options = options.AllowAnyOrigin()); and in the public void ConfigureServices method add the following: services.AddCors(c = { c.AddPolicy( AllowOrigin , options = options.AllowAnyOrigin()); }); Recompile your api application by pressing Ctrl+c and then dotnet run again. Refresh your website at http://localhost:6000 (or https://localhost:6001) and you should be good to go and see the name you added when posted some data in the players method when testing the API. ViewData Dictionary Right so back to the C# question and the Razor syntax. In the model of a razor page (same file name, but with a cs extension) you will see a Get() method. Inside of this method you can add the ViewData dictionary and do some serverside coding so that you can pass the result onto the View. At the top of the cshtml file you will see this piece of code: @ { ViewData [ Title ] = API Page ; ViewData [ ApiType ] = Player Data ; } Inside of the Model of the page you can code any C# methods and place the value of them inside the ViewData Dictionary. This can be useful if you want to set the title dynamically or other content. The idea of clean coding is that you keep your content out of the HTML page, so this way you can keep that from happening. @Renders Inside of a _Layout.cshtml file you will see the keyword @Render like: @RenderBody() @RenderSection(\"Scripts\", required: false) The _Layout.cshtml file is the main template for your website and each of the other .cshtml file is a section of the main page. Any bit of code that is common between each page, is placed in the _Layout.cshtml page. Where ever the @RenderBody() is placed, the view for the particular URL is placed. Conclusion So now you have it - a complete web api that you can view through a website. You write the websites backend in C# and you write the front end in whatever you feel like. if it is a webpage you just use JavaScript. if it a mobile or desktop app, you use whatever the platform offers to parse JSON data.","title":"Consuming the API"},{"location":"dotnet_core/SQLSVR_WEBAPI/dotnet-2.1.x/05-adding-a-web-form/#consuming_the_api","text":"Now that the api is working, we need to be able to interact with it. A normal user isn't going to use postman - they don't even want to know they are using an API.","title":"Consuming the API"},{"location":"dotnet_core/SQLSVR_WEBAPI/dotnet-2.1.x/05-adding-a-web-form/#setting_up_the_project","text":"The purpose of the api is deliver content in such a way that it can be consumed by 1 or more applications. This is why an api should be setup in its own project. For that reason we are now going to create a new project that consumes our api. At the moment we have the following structure: root |--.vscode/ |--api/ |--sql/ |--global.json |--.git/ # you may not see this folder, but it is there if you use git |--.gitignore For this project to work we are going to expand it to the following folder structure: root |--.vscode/ |--api/ |--web/ |--sql/ |--global.json |--.git/ # you may not see this folder, but it is there if you use git |--.gitignore Separating the project This project is still maintained in a single repository. The main focus is still the api, the web component is a means to make sure people can see an implementation of it. For this part you will need to be in the webapi folder, so you have to type in cd .. in the terminal. The prompt should now say webapi . In the api folder we have the actual api, this was created using the dotnet new webapi -o api command. For the web project we are going to use the following command: dotnet new webapp -o web --no-https We are able to use frameworks like react (these templates are offered by dotnet), but let's focus on interacting with the api. Let's also make sure our api is running: dotnet run -p api Since our terminal is now taken up by the application, we need to open another one. Just click the + symbol at the top of the terminal, if you are using the integrated terminal - this will create another terminal instance.","title":"Setting up the project"},{"location":"dotnet_core/SQLSVR_WEBAPI/dotnet-2.1.x/05-adding-a-web-form/#changing_some_settings_in_the_web_project","text":"Next we need to change the port on which the web project runs, since the api takes up port 5000. In the launchsettings.json file, change the port on line 21 from 5000 to 6000 . If you didn't use the --no-https flag when creating the project, you will also need to change 5001 into 6001 for the https port. Run the project by using dotnet run and you will see that you now have 2 dotnet services running. You can now see your project on https://localhost:6001 or http://localhost:6000","title":"Changing some settings in the web project"},{"location":"dotnet_core/SQLSVR_WEBAPI/dotnet-2.1.x/05-adding-a-web-form/#cleaning_up_the_project","text":"The webapp template comes with a lot of boilerplate code that we don't need, so let's remove and change some files: Remove the following files in the Pages folder: About.cshtml About.cshtml.cs Contact.cshtml Contact.cshtml.cs Error.cshtml Error.cshtml.cs Privacy.cshtml Privacy.cshtml.cs Index.cshtml file @page @model IndexModel @{ ViewData[ Title ] = API Page ; ViewData[ ApiType ] = Player Data ; } h1 @ViewData[ Title ] /h1 h2 @ViewData[ ApiType ] /h2 div id= data ul /ul /div Change the Pages/Shared/_Layout.cshtml file into this: _Layout.cshtml file !DOCTYPE html html head meta charset= utf-8 / meta name= viewport content= width=device-width, initial-scale=1.0 / title @ViewData[ Title ] - web /title link rel= stylesheet href= ~/lib/bootstrap/dist/css/bootstrap.css / link rel= stylesheet href= ~/css/site.css / /head body nav class= navbar navbar-inverse navbar-fixed-top div class= container div class= navbar-header button type= button class= navbar-toggle data-toggle= collapse data-target= .navbar-collapse span class= sr-only Toggle navigation /span span class= icon-bar /span span class= icon-bar /span span class= icon-bar /span /button a asp-page= /Index class= navbar-brand web /a /div div class= navbar-collapse collapse ul class= nav navbar-nav li a asp-page= /Index Home /a /li /ul /div /div /nav div class= container body-content @RenderBody() hr / footer p copy; 2019 - web /p /footer /div @RenderSection( Scripts , required: false) /body /html You may notice a few odd symbols - we look at them later, so don't worry about them for now.","title":"Cleaning up the project"},{"location":"dotnet_core/SQLSVR_WEBAPI/dotnet-2.1.x/05-adding-a-web-form/#project_setup","text":"In the wwwroot folder is all of our static and public accessible stuff like images, css and javascript files. We won't really touch them, but that is where they are if you need to find them. In the Pages folder are all the dynamic files. The .cshtml.cs files are the View - the things we see in the web browser. the .cs file with the same name is the code-behind for that page. These pages are reffered to as Razor pages. Razor pages still use the Model View Controller Setup, but it is a bit easier to manage them.","title":"Project Setup"},{"location":"dotnet_core/SQLSVR_WEBAPI/dotnet-2.1.x/05-adding-a-web-form/#first_api_call","text":"Let's get something from our API on the page. To get something on the page we need to make an api call and that api call is going to return to us a JSON string. So getting remote data onto our website from an api is done using Javascript - No C# involved here (but we will add some later on). Add this simple fetch request to your Index.cshtml page inside a set script tags. fetch ( https://localhost:5001/api/players ) . then ( res = res . json ()) . then ( data = { let players = data . map ( d = ` li ${ d . name } /li ` ) document . querySelector ( #data ul ). innerHTML = players }) You will get a CORS (Cross-Origin Resource Sharing) error, since your api and web page are on a different URL. Back in the API project, you will need to enable CORS and for now, we are just going allow it. You will need to tighten up the security when you are in the production stage of your code. Allowing CORS is easy and it is all done in your Startup.cs file. In the public void Configure method add the following middleware: app.UseCors(options = options.AllowAnyOrigin()); and in the public void ConfigureServices method add the following: services.AddCors(c = { c.AddPolicy( AllowOrigin , options = options.AllowAnyOrigin()); }); Recompile your api application by pressing Ctrl+c and then dotnet run again. Refresh your website at http://localhost:6000 (or https://localhost:6001) and you should be good to go and see the name you added when posted some data in the players method when testing the API.","title":"First API Call"},{"location":"dotnet_core/SQLSVR_WEBAPI/dotnet-2.1.x/05-adding-a-web-form/#viewdata_dictionary","text":"Right so back to the C# question and the Razor syntax. In the model of a razor page (same file name, but with a cs extension) you will see a Get() method. Inside of this method you can add the ViewData dictionary and do some serverside coding so that you can pass the result onto the View. At the top of the cshtml file you will see this piece of code: @ { ViewData [ Title ] = API Page ; ViewData [ ApiType ] = Player Data ; } Inside of the Model of the page you can code any C# methods and place the value of them inside the ViewData Dictionary. This can be useful if you want to set the title dynamically or other content. The idea of clean coding is that you keep your content out of the HTML page, so this way you can keep that from happening.","title":"ViewData Dictionary"},{"location":"dotnet_core/SQLSVR_WEBAPI/dotnet-2.1.x/05-adding-a-web-form/#renders","text":"Inside of a _Layout.cshtml file you will see the keyword @Render like: @RenderBody() @RenderSection(\"Scripts\", required: false) The _Layout.cshtml file is the main template for your website and each of the other .cshtml file is a section of the main page. Any bit of code that is common between each page, is placed in the _Layout.cshtml page. Where ever the @RenderBody() is placed, the view for the particular URL is placed.","title":"@Renders"},{"location":"dotnet_core/SQLSVR_WEBAPI/dotnet-2.1.x/05-adding-a-web-form/#conclusion","text":"So now you have it - a complete web api that you can view through a website. You write the websites backend in C# and you write the front end in whatever you feel like. if it is a webpage you just use JavaScript. if it a mobile or desktop app, you use whatever the platform offers to parse JSON data.","title":"Conclusion"},{"location":"git/00_Installing_git/","text":"Installing git Git be installed in several ways and it depends on your operating system and other tooling you have installed. Git Bash The simplest way would probably be to download the executable from: https://git-scm.com/download and choose your operating system GitHub App GitHub provides an extensive crossplatform app that installs git on the command line. You can get the app from: https://desktop.github.com For Windows 10 Home edition and older versions of windows, those are pretty much your only options. For Windows 10 Pro and higher, you can also install WSL (Windows Subsystem for Linux) and then you can install git using a Linux Package Manager. Chocolatey (for Windows) Chocolatey is a cli tool for windows that can be used to install applications, instead of using GUI setups. You can find git on there by click here You will need to install Chocolatey first, and those instructions are here Xcode CLI Tools (for Mac) On a mac, you can install xcode command line tools, which installs git, by typing the following into the terminal: xcode-select --install Brew (for Mac) Brew is a cli tool for macOS that can be used to install applications, instead of using GUI setups. You can install Brew using: /usr/bin/ruby -e $(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install) Brew installs the xcode cli tool, which also installs git. However if you want to update or explicitly install Git, then run: brew install git Linux (Debian based) Use the following command from the terminal: sudo apt-get update sudo apt-get install -y git","title":"Installing git"},{"location":"git/00_Installing_git/#installing_git","text":"Git be installed in several ways and it depends on your operating system and other tooling you have installed.","title":"Installing git"},{"location":"git/00_Installing_git/#git_bash","text":"The simplest way would probably be to download the executable from: https://git-scm.com/download and choose your operating system","title":"Git Bash"},{"location":"git/00_Installing_git/#github_app","text":"GitHub provides an extensive crossplatform app that installs git on the command line. You can get the app from: https://desktop.github.com For Windows 10 Home edition and older versions of windows, those are pretty much your only options. For Windows 10 Pro and higher, you can also install WSL (Windows Subsystem for Linux) and then you can install git using a Linux Package Manager.","title":"GitHub App"},{"location":"git/00_Installing_git/#chocolatey_for_windows","text":"Chocolatey is a cli tool for windows that can be used to install applications, instead of using GUI setups. You can find git on there by click here You will need to install Chocolatey first, and those instructions are here","title":"Chocolatey (for Windows)"},{"location":"git/00_Installing_git/#xcode_cli_tools_for_mac","text":"On a mac, you can install xcode command line tools, which installs git, by typing the following into the terminal: xcode-select --install","title":"Xcode CLI Tools (for Mac)"},{"location":"git/00_Installing_git/#brew_for_mac","text":"Brew is a cli tool for macOS that can be used to install applications, instead of using GUI setups. You can install Brew using: /usr/bin/ruby -e $(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install) Brew installs the xcode cli tool, which also installs git. However if you want to update or explicitly install Git, then run: brew install git","title":"Brew (for Mac)"},{"location":"git/00_Installing_git/#linux_debian_based","text":"Use the following command from the terminal: sudo apt-get update sudo apt-get install -y git","title":"Linux (Debian based)"},{"location":"git/01_what_is_git/","text":"What is git GIT \u2013 Global Information Tracker This is not a coding language, but it is a way (the most common way) to manage our code Git tracks any changes you make in your code and it allows you to manage those changes and share your code with others Git is created by Linus Torvalds The guy who wrote the original linux kernel and git was developed for helping with the development of linux He gave Git the name because of the british meaning of the word. (an unpleasant or contemptible person.) However the official readme file of the git repository calls the system \"Global Information Tracker\" Git itself does not have a GUI or a web interface, it is completely command line based, however: GitHub is the most well known web based system that hosts git repositories and has recently been acquired by Microsoft. Bitbucket (owned by Atlassian) and Gitlab (an open source self hosted option) are others that have a wide reach. How does git work Before having a look at git, let\u2019s have a quick look at what it does. The features that git offers are not always easy to get your head around. While we may see \u201cmanaging code\u201d as a way to save our code, if that is all we do then Git is a cumbersome way to do so. A USB drive would be a lot easier With Git we can do so much more! Within Managing Code we can do: Feature Description Branches Using Branches we can create features and fix bugs without directly affecting your main code Partial Commits Using Partial Commits we can create a more detailed history Decentralised Development Git does not rely on a central server for you to work on. Share your code You can give your code to someone else, but they can only submit changes to it if you give them access to it Multiple Devices, Multiple Locations You are no longer limited to the machine in your office Some features are implemented by 3 rd party products: Feature Description Pull Requests When you have worked on some code from someone else, you will need to notify the owner or a contributor, this is done using a pull request. Public and Private Repositories If you want to clone a repository without the owners knowledge, the repository has to be public, otherwise you need to be given access. The master branch The master branch is a what is first created when you do your first commit. When starting to learning git you will be ok to just use this, but as soon as you start working in a team or have something that is in production (i.e. something people can see and work with) you will want to start exploring working with branches. Tracking Files - Not Folders Git tracks files, not folders So when you setup your folder structure for a project, make sure there is a file in there so git can create a path to that file. If a path to a file includes a folder, it will store those folders If you don\u2019t have a file for a folder yet, create a file can call it .gitkeep This can be deleted later on if need be, but won\u2019t cause issues if you leave it in there Git and Windows Although git's origin lie in linux, macOS and Windows have the use of git deep baked into their development cycles. All common IDE's and most code editors have git build right in, or else there are plenty of tools that can help you out. First we are going to look at the commands using the command line, so that when you explore the GUI options, you will be familiar with the terminology.","title":"What is git"},{"location":"git/01_what_is_git/#what_is_git","text":"GIT \u2013 Global Information Tracker This is not a coding language, but it is a way (the most common way) to manage our code Git tracks any changes you make in your code and it allows you to manage those changes and share your code with others Git is created by Linus Torvalds The guy who wrote the original linux kernel and git was developed for helping with the development of linux He gave Git the name because of the british meaning of the word. (an unpleasant or contemptible person.) However the official readme file of the git repository calls the system \"Global Information Tracker\" Git itself does not have a GUI or a web interface, it is completely command line based, however: GitHub is the most well known web based system that hosts git repositories and has recently been acquired by Microsoft. Bitbucket (owned by Atlassian) and Gitlab (an open source self hosted option) are others that have a wide reach.","title":"What is git"},{"location":"git/01_what_is_git/#how_does_git_work","text":"Before having a look at git, let\u2019s have a quick look at what it does. The features that git offers are not always easy to get your head around. While we may see \u201cmanaging code\u201d as a way to save our code, if that is all we do then Git is a cumbersome way to do so. A USB drive would be a lot easier With Git we can do so much more! Within Managing Code we can do: Feature Description Branches Using Branches we can create features and fix bugs without directly affecting your main code Partial Commits Using Partial Commits we can create a more detailed history Decentralised Development Git does not rely on a central server for you to work on. Share your code You can give your code to someone else, but they can only submit changes to it if you give them access to it Multiple Devices, Multiple Locations You are no longer limited to the machine in your office Some features are implemented by 3 rd party products: Feature Description Pull Requests When you have worked on some code from someone else, you will need to notify the owner or a contributor, this is done using a pull request. Public and Private Repositories If you want to clone a repository without the owners knowledge, the repository has to be public, otherwise you need to be given access.","title":"How does git work"},{"location":"git/01_what_is_git/#the_master_branch","text":"The master branch is a what is first created when you do your first commit. When starting to learning git you will be ok to just use this, but as soon as you start working in a team or have something that is in production (i.e. something people can see and work with) you will want to start exploring working with branches.","title":"The master branch"},{"location":"git/01_what_is_git/#tracking_files_-_not_folders","text":"Git tracks files, not folders So when you setup your folder structure for a project, make sure there is a file in there so git can create a path to that file. If a path to a file includes a folder, it will store those folders If you don\u2019t have a file for a folder yet, create a file can call it .gitkeep This can be deleted later on if need be, but won\u2019t cause issues if you leave it in there","title":"Tracking Files - Not Folders"},{"location":"git/01_what_is_git/#git_and_windows","text":"Although git's origin lie in linux, macOS and Windows have the use of git deep baked into their development cycles. All common IDE's and most code editors have git build right in, or else there are plenty of tools that can help you out. First we are going to look at the commands using the command line, so that when you explore the GUI options, you will be familiar with the terminology.","title":"Git and Windows"},{"location":"git/02_basic_commands/","text":"Basic Commands To be able to use git we need to know a bit about the command line. Some of these commands you may already be familiar with, so just have a look through them. First let's get to know how to navigate through locations Location Description . Current Folder .. Parent Folder ~ Home Directory / The root of a drive, you cannot go any higher than this folder A folder name that is in the current folder you are in, ignore the angle brackets folder / file Path to a file, the file may be in a sub folder ls -la ls = list files, -l = long list, -a = show all files, including hidden As mentioned earlier, git is a linux command line tool - so we need to know some basic commands to find our way around. Feature Description cd change directory - this is followed by location above mkdir folder create a folder, ignore the angle brackets touch file create a file, ignore the angle brackets mkdir -p folder create a folder with subfolders rm remove a file followed by the file name rm -f force remove a file followed by the file name rm -rf force remove a folder followed by the folder name mv source file/path destination file/path Moving or Renaming files Basic git commands Next up are the basic git commands. Even though we are still going to cover them in more detail - here is a list of them for a quick reference. Feature Description git init Create a git repository in your current folder git init folder name Create a folder with a git repository in it. Ignore the angle brackets git add . or git add --all Add all the files to the staging stage, this includes new, updated and deleted files git add -u Add only new and updated files to the staging stage git commit -m \"message\" Add the files to the git repository and create a log point git push origin master Push the current content in your local repository to your remote repository git pull origin master Pull the current content from the remote repository to your local repository git clone repo-link Clone an existing remote repository to your local folder, it creates a folder with the repository name git clone repo-link . Clone an existing remote repository to your local folder, but places all the content in the current folder. This folder must be blank. Some gotcha's Often people will do a git init without navigating their terminal to the right location first. Do not create a git repository inside of another git repository as it messes up the tracking system. If you do not create any branches, then you must use git pull and git push correctly often, but this is a bad way of working, but we will get back to that later. Intitial Git Setup After you setup a git repository using git init you will want to let git know who is making the commits. In most cases you will only need to do this once per machine. git config --global user.name Your name git config --global user.email Your email If you want to override these settings for a particular project then you can use the local flag instead of the global one. The local flag will only apply to the repository you are working on. git config --local user.name Your name git config --local user.email Your email","title":"Basic Commands"},{"location":"git/02_basic_commands/#basic_commands","text":"To be able to use git we need to know a bit about the command line. Some of these commands you may already be familiar with, so just have a look through them. First let's get to know how to navigate through locations Location Description . Current Folder .. Parent Folder ~ Home Directory / The root of a drive, you cannot go any higher than this folder A folder name that is in the current folder you are in, ignore the angle brackets folder / file Path to a file, the file may be in a sub folder ls -la ls = list files, -l = long list, -a = show all files, including hidden As mentioned earlier, git is a linux command line tool - so we need to know some basic commands to find our way around. Feature Description cd change directory - this is followed by location above mkdir folder create a folder, ignore the angle brackets touch file create a file, ignore the angle brackets mkdir -p folder create a folder with subfolders rm remove a file followed by the file name rm -f force remove a file followed by the file name rm -rf force remove a folder followed by the folder name mv source file/path destination file/path Moving or Renaming files","title":"Basic Commands"},{"location":"git/02_basic_commands/#basic_git_commands","text":"Next up are the basic git commands. Even though we are still going to cover them in more detail - here is a list of them for a quick reference. Feature Description git init Create a git repository in your current folder git init folder name Create a folder with a git repository in it. Ignore the angle brackets git add . or git add --all Add all the files to the staging stage, this includes new, updated and deleted files git add -u Add only new and updated files to the staging stage git commit -m \"message\" Add the files to the git repository and create a log point git push origin master Push the current content in your local repository to your remote repository git pull origin master Pull the current content from the remote repository to your local repository git clone repo-link Clone an existing remote repository to your local folder, it creates a folder with the repository name git clone repo-link . Clone an existing remote repository to your local folder, but places all the content in the current folder. This folder must be blank.","title":"Basic git commands"},{"location":"git/02_basic_commands/#some_gotchas","text":"Often people will do a git init without navigating their terminal to the right location first. Do not create a git repository inside of another git repository as it messes up the tracking system. If you do not create any branches, then you must use git pull and git push correctly often, but this is a bad way of working, but we will get back to that later.","title":"Some gotcha's"},{"location":"git/02_basic_commands/#intitial_git_setup","text":"After you setup a git repository using git init you will want to let git know who is making the commits. In most cases you will only need to do this once per machine. git config --global user.name Your name git config --global user.email Your email If you want to override these settings for a particular project then you can use the local flag instead of the global one. The local flag will only apply to the repository you are working on. git config --local user.name Your name git config --local user.email Your email","title":"Intitial Git Setup"},{"location":"git/03_how_does_git_work/","text":"How does it all work? Without git, you can create and save files inside of a folder and there is a single version of those files. In addition when you keep working on those files, you are always working with the latest version of those files. When you add a git repository inside of your folder, you gain the ability to create snapshots of those files. These are not copies, but rather a marker of a point in time of your code. There is always only one folder or file, but you can switch between different versions of the file by going back to previous snapshots. These snapshots are recorded once you do a commit. So by doing frequent commits you are able to back and forward to different versions of your project. Tip When you have finished a component of your work, make a commit. Your page or screen may not be finished yet, but your code may have changed enough for you not to want to redo that task if something goes wrong What are commits Previously we talked about the master branch and when you do your first commit, this master branch is created. A commit is identified by a SHA-1 key and is made up of 40 hexadecimal (0 - F) characters like this: 8bfecf283eb5e471dcdbf52f9567bf05a9e159c7 Each of these numbers is unique and the amount of combinations is so big that you will unlikely get a duplicate key. Funfact : As a proof of concept of the above the entire linux kernel has 839,314 commits pushed up to its GitHub page as of 19/05/2019 and has not run into duplicate numbers yet. When referencing to these commit numbers, you will likely find that selecting the first 7 digits is enough since it gives you 268,435,456 different combinations alone. Each of these commits is a snapshot of you chose to commit , so it may not include everything. Commits include more details than just a number and when running git log you see something like this: commit 1df4bcf0f0a550e22d33acd1005f03f7e3aa771d ( HEAD - master ) Author: Jeffrey Kranenburg jeff_mba@MBA.local Date: Sun May 19 14 :29:51 2019 +1200 First commit Commit number - The commit number and that the HEAD is matched to the master Author - Who made the commit Date - When the commit was made Commit message - This message should be less than 50 characters Go back to the last commit As long as the .git folder is in place, you can always recover files from a previous snapshot (or commit) even if you delete it. For this use git checkout .","title":"How does it all work?"},{"location":"git/03_how_does_git_work/#how_does_it_all_work","text":"Without git, you can create and save files inside of a folder and there is a single version of those files. In addition when you keep working on those files, you are always working with the latest version of those files. When you add a git repository inside of your folder, you gain the ability to create snapshots of those files. These are not copies, but rather a marker of a point in time of your code. There is always only one folder or file, but you can switch between different versions of the file by going back to previous snapshots. These snapshots are recorded once you do a commit. So by doing frequent commits you are able to back and forward to different versions of your project. Tip When you have finished a component of your work, make a commit. Your page or screen may not be finished yet, but your code may have changed enough for you not to want to redo that task if something goes wrong","title":"How does it all work?"},{"location":"git/03_how_does_git_work/#what_are_commits","text":"Previously we talked about the master branch and when you do your first commit, this master branch is created. A commit is identified by a SHA-1 key and is made up of 40 hexadecimal (0 - F) characters like this: 8bfecf283eb5e471dcdbf52f9567bf05a9e159c7 Each of these numbers is unique and the amount of combinations is so big that you will unlikely get a duplicate key. Funfact : As a proof of concept of the above the entire linux kernel has 839,314 commits pushed up to its GitHub page as of 19/05/2019 and has not run into duplicate numbers yet. When referencing to these commit numbers, you will likely find that selecting the first 7 digits is enough since it gives you 268,435,456 different combinations alone. Each of these commits is a snapshot of you chose to commit , so it may not include everything. Commits include more details than just a number and when running git log you see something like this: commit 1df4bcf0f0a550e22d33acd1005f03f7e3aa771d ( HEAD - master ) Author: Jeffrey Kranenburg jeff_mba@MBA.local Date: Sun May 19 14 :29:51 2019 +1200 First commit Commit number - The commit number and that the HEAD is matched to the master Author - Who made the commit Date - When the commit was made Commit message - This message should be less than 50 characters Go back to the last commit As long as the .git folder is in place, you can always recover files from a previous snapshot (or commit) even if you delete it. For this use git checkout .","title":"What are commits"},{"location":"git/04_basic_workflow/","text":"Basic Workflow Git can be used in a couple of ways. The 2 main ones are: Local first - Creating a repository locally on your machine Remote first - Cloning a repository Local first Local first is used when you already have a project on your machine, or want to just start on your own machine before pushing your code anywhere. To start your repository locally use the git init command. Personally I have a project folder in my users folder called Code and inside of there I have my repositories, so this is my workflow: cd ~/Code git init project cd project Then I setup project and before writing any code, I do an initial commit: git add -A git commit -m Initial Commit If you see a \" \" on yoru screen, you probably forgot the closing quotation mark of the git commit. To exit out of that type in Ctrl+C and start again. Adding a remote connection Now if you want to be able to push this code a remote repository, you need to create a repository on GitHub and then use the url to that repository to link your local repository to your remote repository. Go to https://github.com/new to get started. Name your repository and give it an optional description Set the repository to public or private (both are free) Ignore the \"Initialize this repository with a README\" checkbox. Now that you have a remote repository setup you need to link it by typing in: git remote add origin url-to-repo If you mistype anything, you can remove a link by typing in: git remote rm origin Origin is the default name for the remote connection. Now you can \"push\" your code to the remote repository using: git push origin master Remote first If there is a repository already created on GitHub, then you can use that as a base. For this, you will need to clone the repository: git clone url-to-repo This will create a folder with the repository in it. My workflow for this is: cd ~/Code git clone url-to-repo cd project After this you will see the code from the project and you can just start working on it. A couple of things to note: If this is not your own repository, you cannot push to it unless you have permission to do so. If you want to push to it without permissions, you need to fork* it first, but it will never be merged into the original repository and you won't receive updates for it after the date you forked it. When you clone a repository, it already includes the remote connection since it came from a remote place. So adding another remote connection is possible, but not required. The steps above are the very minimum you need to do to work with git, but there is much more to it - which we will look into next. Git Reset Since we can add and update files to a git repository, it would be useful if we can go back to a previous state. Here are some of the basic options you have. Command Description git reset --soft sha1 number does not change any of your files, but goes back the referenced commit (keeps the files in the staging tree) git reset --mixed sha1 number changes the files in the working area git reset sha1 number same as git reset --mixed sha1 number git reset --hard sha1 number goes back to the referenced commit reverting back all changes git checkout -- index.html Reverses the changes of a file to the most recent commit git commit --amend Change the last commit message in a vim editor git commit --amend -m \"msg\" Change the last commit message inline From there you can recommit or make any changes you need.","title":"Basic Workflow"},{"location":"git/04_basic_workflow/#basic_workflow","text":"Git can be used in a couple of ways. The 2 main ones are: Local first - Creating a repository locally on your machine Remote first - Cloning a repository","title":"Basic Workflow"},{"location":"git/04_basic_workflow/#local_first","text":"Local first is used when you already have a project on your machine, or want to just start on your own machine before pushing your code anywhere. To start your repository locally use the git init command. Personally I have a project folder in my users folder called Code and inside of there I have my repositories, so this is my workflow: cd ~/Code git init project cd project Then I setup project and before writing any code, I do an initial commit: git add -A git commit -m Initial Commit If you see a \" \" on yoru screen, you probably forgot the closing quotation mark of the git commit. To exit out of that type in Ctrl+C and start again.","title":"Local first"},{"location":"git/04_basic_workflow/#adding_a_remote_connection","text":"Now if you want to be able to push this code a remote repository, you need to create a repository on GitHub and then use the url to that repository to link your local repository to your remote repository. Go to https://github.com/new to get started. Name your repository and give it an optional description Set the repository to public or private (both are free) Ignore the \"Initialize this repository with a README\" checkbox. Now that you have a remote repository setup you need to link it by typing in: git remote add origin url-to-repo If you mistype anything, you can remove a link by typing in: git remote rm origin Origin is the default name for the remote connection. Now you can \"push\" your code to the remote repository using: git push origin master","title":"Adding a remote connection"},{"location":"git/04_basic_workflow/#remote_first","text":"If there is a repository already created on GitHub, then you can use that as a base. For this, you will need to clone the repository: git clone url-to-repo This will create a folder with the repository in it. My workflow for this is: cd ~/Code git clone url-to-repo cd project After this you will see the code from the project and you can just start working on it. A couple of things to note: If this is not your own repository, you cannot push to it unless you have permission to do so. If you want to push to it without permissions, you need to fork* it first, but it will never be merged into the original repository and you won't receive updates for it after the date you forked it. When you clone a repository, it already includes the remote connection since it came from a remote place. So adding another remote connection is possible, but not required. The steps above are the very minimum you need to do to work with git, but there is much more to it - which we will look into next.","title":"Remote first"},{"location":"git/04_basic_workflow/#git_reset","text":"Since we can add and update files to a git repository, it would be useful if we can go back to a previous state. Here are some of the basic options you have. Command Description git reset --soft sha1 number does not change any of your files, but goes back the referenced commit (keeps the files in the staging tree) git reset --mixed sha1 number changes the files in the working area git reset sha1 number same as git reset --mixed sha1 number git reset --hard sha1 number goes back to the referenced commit reverting back all changes git checkout -- index.html Reverses the changes of a file to the most recent commit git commit --amend Change the last commit message in a vim editor git commit --amend -m \"msg\" Change the last commit message inline From there you can recommit or make any changes you need.","title":"Git Reset"},{"location":"git/05_basic_workflow_images/","text":"Git stages Working Directory When we code, we are working in a folder, this folder is called the working directory You can save your work in this folder, but a normal save won\u2019t add it to the repository. If you delete that file - it is gone, just like a normal file would be. When using the command git status you can see that the files are listed in red Staging Stage The staging area lists the files in green When the files are in the staging area, they are being setup to be committed into the repository Once they are committed into the repository they are tracked and you will be able to see the changes from the previous commit. Commit Stage Once you have committed the files they are part f the repository and any future changes are able to be compared to what is currently in the repository After you make the first commit, the master branch is created and that is the branch that all other changes will be based off Git Log When we do a git log command we see the numbers appear This is very handy to authenticate our code, but also to go back to previous commits if we need to","title":"Git stages"},{"location":"git/05_basic_workflow_images/#git_stages","text":"","title":"Git stages"},{"location":"git/05_basic_workflow_images/#working_directory","text":"When we code, we are working in a folder, this folder is called the working directory You can save your work in this folder, but a normal save won\u2019t add it to the repository. If you delete that file - it is gone, just like a normal file would be. When using the command git status you can see that the files are listed in red","title":"Working Directory"},{"location":"git/05_basic_workflow_images/#staging_stage","text":"The staging area lists the files in green When the files are in the staging area, they are being setup to be committed into the repository Once they are committed into the repository they are tracked and you will be able to see the changes from the previous commit.","title":"Staging Stage"},{"location":"git/05_basic_workflow_images/#commit_stage","text":"Once you have committed the files they are part f the repository and any future changes are able to be compared to what is currently in the repository After you make the first commit, the master branch is created and that is the branch that all other changes will be based off","title":"Commit Stage"},{"location":"git/05_basic_workflow_images/#git_log","text":"When we do a git log command we see the numbers appear This is very handy to authenticate our code, but also to go back to previous commits if we need to","title":"Git Log"},{"location":"git/06_branches/","text":"Using Branches Up until this point we have looked at the master branch. The master branch is the main branch and most commonly used to have the code that is currently in production (i.e. the version of the code users currently see) As you may imagine, this is not a good place to make continous changes. Branches - just like commits - are snapshots, but these snapshots allow us to make adjustments to our code and test them separately from the master branch. A number of uses for branches are: Feature Development Bug Fixes (fixes or improvements of an app) Hot Fixes (fixes or improvements of an app that are out of cycle) Testing Building towards release Why is it called a branch? No reason other than terminology. Each code commit contains what is known as a tree - this is a list of all the files in the current code base. Source: https://git-scm.com/book/en/v2/Git-Branching-Branches-in-a-Nutshell A branch is a snapshot of that tree. The HEAD is the place where you are currently on and represents the \"space\" between the last commit and your current changes and it moves when you switch to another branch. To create a branch you will need to type in: git branch branch-name The above command creates the new branch, but you are not switching to it. git checkout -b branch-name The above command will create a new branch from the position your HEAD is currently at and switches you to it. git checkout -b new-branch-name other-branch-name The above command will create a new branch with the starting point being another branch and switches you to it, this saves you having to switch back to other braches first. Good Practice Each time you add a new feature, create a branch for it. That way when you add someone to your team they can work of what is already there and your code won't accidently be erased.","title":"Using Branches"},{"location":"git/06_branches/#using_branches","text":"Up until this point we have looked at the master branch. The master branch is the main branch and most commonly used to have the code that is currently in production (i.e. the version of the code users currently see) As you may imagine, this is not a good place to make continous changes. Branches - just like commits - are snapshots, but these snapshots allow us to make adjustments to our code and test them separately from the master branch. A number of uses for branches are: Feature Development Bug Fixes (fixes or improvements of an app) Hot Fixes (fixes or improvements of an app that are out of cycle) Testing Building towards release Why is it called a branch? No reason other than terminology. Each code commit contains what is known as a tree - this is a list of all the files in the current code base. Source: https://git-scm.com/book/en/v2/Git-Branching-Branches-in-a-Nutshell A branch is a snapshot of that tree. The HEAD is the place where you are currently on and represents the \"space\" between the last commit and your current changes and it moves when you switch to another branch. To create a branch you will need to type in: git branch branch-name The above command creates the new branch, but you are not switching to it. git checkout -b branch-name The above command will create a new branch from the position your HEAD is currently at and switches you to it. git checkout -b new-branch-name other-branch-name The above command will create a new branch with the starting point being another branch and switches you to it, this saves you having to switch back to other braches first. Good Practice Each time you add a new feature, create a branch for it. That way when you add someone to your team they can work of what is already there and your code won't accidently be erased.","title":"Using Branches"},{"location":"git/07_gitignore/","text":"Gitignore When using git there are files that we don\u2019t want to be tracked. We only want to track the files that we directly use to develop the project. Files (like frameworks and libraries) can easily be imported as part of an import process and do not need to be put into version control. When developing software we also deal with system files and binary files. We want to keep those out of version control as well. For this we use .gitignore Eventually you will know what the files are that you want to include in the .gitignore file and the files will be different from project to project, depending on what language(s), framework(s) and libraries you are using. However there are some common ones are: .DS_Store (a system file on a mac) even if you are on Windows you do not know if other people might use a mac .env This is where you store your environment variables Anything web include node_modules when creating a website and using npm packages. vendor if you are using php Anything dotnet at a minimum include bin/ obj/ You can find a list of gitignore files here: https://github.com/github/gitignore","title":"Gitignore"},{"location":"git/07_gitignore/#gitignore","text":"When using git there are files that we don\u2019t want to be tracked. We only want to track the files that we directly use to develop the project. Files (like frameworks and libraries) can easily be imported as part of an import process and do not need to be put into version control. When developing software we also deal with system files and binary files. We want to keep those out of version control as well. For this we use .gitignore Eventually you will know what the files are that you want to include in the .gitignore file and the files will be different from project to project, depending on what language(s), framework(s) and libraries you are using. However there are some common ones are: .DS_Store (a system file on a mac) even if you are on Windows you do not know if other people might use a mac .env This is where you store your environment variables Anything web include node_modules when creating a website and using npm packages. vendor if you are using php Anything dotnet at a minimum include bin/ obj/ You can find a list of gitignore files here: https://github.com/github/gitignore","title":"Gitignore"},{"location":"git/08_exercises/","text":"Exercises These exercises are all done using git bash or the terminal Note for windows users: The unix system outputs paths using forward slashes ( / ) not the backwards slash ( \\ ) So to go to a path on a particular drive type in something like: /d/code This is will take you to D:\\code The unix system is also case sensitive, so D:\\Code is not the same as D:\\code 01 - Create a repository Navigate to a working folder (H:) Create a folder called Code Inside that folder create a folder called project101 Inside that folder create a git repository 02 - Create a second repository Navigate to your working folder (/drive letter/Code) Inside that folder create a folder called project102 that includes a git repository using a single command 03 - Delete a folder Delete folder project102 04 - Create a folder structure Create the following folders: css, images, js Create the following files: index.html, css/style.css, javascript/script.js 05 - Create handy shortcuts Using the symbols, you can run multiple commands on a single line. Create a the same folder structure in a folder called project103 The folder must include a git repository 06 - Create your first commit Open the index.html in your text editor of choice Add the following code h1 Hello World! /h1 Commit the changes to your repository (use \"Initial Commit\") 07 - Git log Type in Git log and study the log so far Make some changes to index.html, by adding: h2 I am learning git /h2 Add a commit with the message \"Update index.html\" Type in Git log and see the changes 08 - Delete the index.html Close the text editor, if it is open Delete the index.html file ( rm index.html ) Get it back using git (it won't be in the recycle bin) 09 - Go back a commit Still in the terminal, go back to the first commit, but make sure your changes of index.html are still there. 10 - create a branch Create a branch called feature/hotdog in the style.css file add the following code: body { background-color: red; color: yellow; } Add the code to your repository (by commiting it) Switch back to your master branch Notice that the style sheet is empty 11 - Merging braches Merge your branches by typing in: git merge master feature/hotdog git branch -d feature/hotdog Type in git branch to check you are on the master branch Check that your stylesheet contains the hotdog colours.","title":"Exercises"},{"location":"git/08_exercises/#exercises","text":"These exercises are all done using git bash or the terminal Note for windows users: The unix system outputs paths using forward slashes ( / ) not the backwards slash ( \\ ) So to go to a path on a particular drive type in something like: /d/code This is will take you to D:\\code The unix system is also case sensitive, so D:\\Code is not the same as D:\\code","title":"Exercises"},{"location":"git/08_exercises/#01_-_create_a_repository","text":"Navigate to a working folder (H:) Create a folder called Code Inside that folder create a folder called project101 Inside that folder create a git repository","title":"01 - Create a repository"},{"location":"git/08_exercises/#02_-_create_a_second_repository","text":"Navigate to your working folder (/drive letter/Code) Inside that folder create a folder called project102 that includes a git repository using a single command","title":"02 - Create a second repository"},{"location":"git/08_exercises/#03_-_delete_a_folder","text":"Delete folder project102","title":"03 - Delete a folder"},{"location":"git/08_exercises/#04_-_create_a_folder_structure","text":"Create the following folders: css, images, js Create the following files: index.html, css/style.css, javascript/script.js","title":"04 - Create a folder structure"},{"location":"git/08_exercises/#05_-_create_handy_shortcuts","text":"Using the symbols, you can run multiple commands on a single line. Create a the same folder structure in a folder called project103 The folder must include a git repository","title":"05 - Create handy shortcuts"},{"location":"git/08_exercises/#06_-_create_your_first_commit","text":"Open the index.html in your text editor of choice Add the following code h1 Hello World! /h1 Commit the changes to your repository (use \"Initial Commit\")","title":"06 - Create your first commit"},{"location":"git/08_exercises/#07_-_git_log","text":"Type in Git log and study the log so far Make some changes to index.html, by adding: h2 I am learning git /h2 Add a commit with the message \"Update index.html\" Type in Git log and see the changes","title":"07 - Git log"},{"location":"git/08_exercises/#08_-_delete_the_indexhtml","text":"Close the text editor, if it is open Delete the index.html file ( rm index.html ) Get it back using git (it won't be in the recycle bin)","title":"08 - Delete the index.html"},{"location":"git/08_exercises/#09_-_go_back_a_commit","text":"Still in the terminal, go back to the first commit, but make sure your changes of index.html are still there.","title":"09 - Go back a commit"},{"location":"git/08_exercises/#10_-_create_a_branch","text":"Create a branch called feature/hotdog in the style.css file add the following code: body { background-color: red; color: yellow; } Add the code to your repository (by commiting it) Switch back to your master branch Notice that the style sheet is empty","title":"10 - create a branch"},{"location":"git/08_exercises/#11_-_merging_braches","text":"Merge your branches by typing in: git merge master feature/hotdog git branch -d feature/hotdog Type in git branch to check you are on the master branch Check that your stylesheet contains the hotdog colours.","title":"11 - Merging braches"},{"location":"git/09_faqs/","text":"GIT FAQ Here are some questions I have run into and hope to answer them below: If I create multiple branches and edit the same file will I get a conflict when I merge them? Technically yes you will, but the way around that is to do the following: Option 1) * Make a change in branch one and push it to the remote repository (GitHub) * Pull the changes into the other branch and fix any conflicts * Merge the final result (after testing) it into the master branch Option 2) * Make a change in branch one and merge it into the other branch * Fix the conflicts * Merge the final result (after testing) it into the master branch Ideally you will not be working on the same files in different branches while they are on your machine. How do I rename a file / folder? Use the mv command Usage is mv source file/path destination file/path","title":"GIT FAQ"},{"location":"git/09_faqs/#git_faq","text":"Here are some questions I have run into and hope to answer them below: If I create multiple branches and edit the same file will I get a conflict when I merge them? Technically yes you will, but the way around that is to do the following: Option 1) * Make a change in branch one and push it to the remote repository (GitHub) * Pull the changes into the other branch and fix any conflicts * Merge the final result (after testing) it into the master branch Option 2) * Make a change in branch one and merge it into the other branch * Fix the conflicts * Merge the final result (after testing) it into the master branch Ideally you will not be working on the same files in different branches while they are on your machine. How do I rename a file / folder? Use the mv command Usage is mv source file/path destination file/path","title":"GIT FAQ"},{"location":"mern/","text":"Creating a Web Api using MERN Setup Setup a Folder into an ENV (Environment Variable) FOLDER = MERN101 Clone the following repository to get your setup curl -LOk https://github.com/to-jk11/mern101-pg/archive/master.zip unzip master.zip rm -f master.zip mv mern101-pg-master $FOLDER You should now have a folder called MERN101 (or whatever you called it and inside of there you should have the following folder structure: root/ | --- .vscode | --- express | --- mongodb | --- react | --- .gitignore Install Extensions In the project there is an extensions.json file which has some recommended extensions for this project. To install there do the following: Open the MERN101 project in VSCODE Open the Extension tab (5 th one down) Type in @recommended in the search bar and install or enable to those extensions if they are not already. Restart vscode if you are being asked too (later versions don't require this) Keep VSCODE open - we won't be leaving it anytime soon :-) Change your terminal into Bash All the commands listed below will work with Bash - but not necessarily with Powershell, therefore if you are on Windows, open up the file settings.json in the .vscode folder and uncomment the terminal line. After this you will need to trash any terminal sessions you have open to see the bash terminal. NPM Install The repository does not come with any of the remote packages installed - so let's do that first. Go into the mern folder = cd react Install node packages = npm i Start the Mongodb server Go up one folder = cd .. Navigate into the mongodb folder = cd mongodb Start the mongod server = mongod --config mongo.conf Terminal window in VSCode is now taken up by the mongod server, so click the + symbol to open another one. Viewing your database files In the left bar of VSCode you should see an icon that looks like the Azure logo. (it is a triangle shaped letter A) From here you should be able to connect to the database by clicking on the \"Attached Database Accounts\" and then \"Attach Database Account...\" The Wizard will take your through the connection steps. Select MongoDB from the list and after that you won't need to change anything. Setup a user and structure for your database In a fresh bash shell (remmember that + you clicked) You can then load the setup file that you find in the mongodb folder. mongo mongo-script setup.js After this you can refresh your db connection in the azure extension and see that the db, collections and user has been created. Setup Express To be able to view our data on a webpage, we need to setup a webserver. We do this using express and node. (The N and E of MERN) If we go back to the MVC model, then this section is setting up the Controller and the Model. Inside of our express, we are going to create a number of api endpoints and then access those later in React - which will serve as the View. In the express folder, there is a package.json file, which contains the packages that we need to install. Make sure you are in the root folder of this project. To check if you are, type in ls -la and you should see the above mentioned root directory structure. drwxr-xr-x 13 jeff_mba staff 416 5 May 19 :57 .git -rw-r--r-- 1 jeff_mba staff 49 5 May 17 :39 .gitignore drwxr-xr-x 4 jeff_mba staff 128 5 May 18 :05 .vscode drwxr-xr-x 3 jeff_mba staff 96 5 May 20 :00 express drwxr-xr-x 6 jeff_mba staff 192 5 May 18 :41 mongodb drwxr-xr-x 9 jeff_mba staff 288 5 May 17 :39 react Go into the express folder = cd express (everything in this section will be in that folder unless otherwise specified) Install the node packages = npm install The rest we need to manually setup. Now we need to setup express, as part of the recommended extensions you will have installed or enabled the express snippets extensions. Setup Server.js Next create an server.js file and use the ex4 followed by the key to give yourself an express template. You will need to make the following changes: On Line 3 add const port = 4000 - react will run on port 3000 later On Line 10 (probably) replace the console.log with this = console . log ( `Server running on port ${ port } ` ); Remove the commented line on line 13 (again probably) Test that your app runs correctly, by typing in npm start in the terminal - this will start the express server using nodemon. (use npm i -g nodemon if you haven't got this installed) Using the browser preview (by clicking on in the left tab) you should be able to navigate to localhost:4000/ and see Hello World on the screen. Creating our Database Models Create a folder and a file in the express folder = mkdir config touch config/keys.js Inside of the keys.js file add the following code: module . exports = { mongoURI : mongodb://admin:admin123@localhost:27017/students } Next we need to create our Model files: mkdir Models touch Models/names.js touch Models/subjects.js In these files, we create the models that we need to match our database Here is the schema for the names collection - you will need to create the schema for the subjects yourself. // Schema definition file for our colour collection data var mongoose = require ( mongoose ); var Schema = mongoose . Schema ; //create a schema description of our color document structure const namesSchema = new Schema ( { _id : Number , name : String }, { collection : names }, { versionKey : false } ); module . exports = Names = mongoose . model ( Names , namesSchema ); Connecting Express to Database Before we create the api, let's make a small adjustment to our server.js file Replace this code: app . get ( / , ( req , res ) = { res . send ( Hello World! ); }); With this: const mongoose = require ( mongoose ); const bodyparser = require ( body-parser ); const namesroute = require ( ./routes/api/namesroute ); const subjectsroute = require ( ./routes/api/subjectsroute ); app . use ( bodyparser . json ()); app . use ( function ( req , res , next ) { res . header ( Access-Control-Allow-Origin , * ); res . header ( Access-Control-Allow-Headers , Origin, X-Requested-With, Content-Type, Accept ); next (); }); app . use ( /api/names , namesroute ); app . use ( /api/subjects , subjectsroute ); const db = require ( ./config/keys ). mongoURI ; mongoose . connect ( db , { useNewURLParser : true }) . then ( function (){ console . log ( MongoDB connected... ); }) . catch ( function ( err ){ console . log ( err ) }); app . get ( / , ( req , res ) = { res . json ({ reply : Route for HOME path. }); }); In the abovde code, we are adding the mongoose and bodyparser middelwares. We are also setting up our api endpoints and connecting to our database. The last part for our server is to add our API routes. Setting up our API CRUD endpoints Still in our express folder, create a new folder called routes and then inside of that folder create another folder called api. mkdir -p express/api Inside of this folder create 2 files: touch routes/api/namesroute.js touch routes/api/subjectsroute.js Again - just like with the model - I will show you the names route and you have to create the subjects route. At the top of a route file type in: const express = require ( express ); const router = express . Router (); const names = require ( ../../models/names ); You won't need to do an npm install for this, since the router is build into express. Each of the endpoints that we cover below we add start with the following comments: //@route GET /api/names //@desc Get all Names from the DB //@access Public We need these, so we can easily identity what each of the routes do for us. Each of the route endpoints is placed after the endpoint set in the server.js file For example - when we define / we get there by typing in /api/names/ as the url. Each of the route endpoints is setup as a javascript promise inside of a javascript object. Get Methods //@route GET /api/names //@desc Get all Names from the DB //@access Public router . get ( / , function ( req , res ){ names . find () . sort ({ name : 1 }) . then ( function ( name ){ res . json ( name ); }) . catch ( function ( err ){ console . log ( err ); }) }); In the above code we do the following: Set the route Set the name of the collection use the find() method that finds all the data sort the data in ascending order present the data to us in json format OR gives us information if there is an error If we have a look at find a single piece of data, the setup is very similar: //@route GET /api/names/:names //@desc Get all Names from the DB matching the parameter //@access Public router . get ( /:name , function ( req , res ){ names . find ({ name : req . params . name }) . sort ({ name : 1 }) . then ( function ( name ){ ( name === 0 ) ? res . json ({ msg : ` ${ req . params . name } does not exist` }) : res . json ( name ); }) . catch ( function ( err ){ console . log ( err ); }) }); In the above code we do the following: Set the route Set the name of the collection use the find({name: req.params.name}) method that finds the data matching the name sort the data in ascending order present the data to us in json format OR gives us information if there is an error For the other routes, we need to deal with the object schema we created earlier: For the POST Method For post we need to read incoming data - this is done using the req.body property. //@route POST /api/names/ //@desc Add a new Name to the DB //@access Public router . post ( / , function ( req , res ){ let newName = new Names ( req . body ); newName . save ( newName ) . then (() = { res . json ({ success : Name Added }); }) . catch ( err = { res . status ( 404 ). json ({ error : err }) }) }); In the above code we do the following: Set the route Instantiate the info from req.body to a new Names object With the new object we call the save function and pass in the object. Return a success message if the object was added successfully OR an error message For the DELETE Method To delete a record we need to know the id. //@route DELETE /api/names/:id //@desc Delete a name from the DB by _id key //@access Public (should be secured) router . delete ( /:id , function ( req , res ){ names . findByIdAndDelete ( req . params . id ) . then ( name = { name . remove (); res . json ({ success : Name Deleted }); }) . catch ( err = { res . status ( 404 ). json ({ error : err }) }) }); In the above code we do the following: Set the route Find the record that matches the id Delete the matching record Return a success message if the object was removed successfully OR an error message For the Update Method For the update method, you will need an id - so only a single object is updated and the content from the form. //@route UPDATE /api/names/:id //@desc Update a Name from the DB by _id key //@access Public (should be secured) router.put( /:id , ( req, res) = { names .findByIdAndUpdate(req.params.id, req.body) .then(name = { name.set(req.body) res.json({ success: Name Updated }); }) .catch(err = { res.status(404).json({ error: err }) }) }); In the above code we do the following: Set the route Find the record that matches the id Call the set method and pass in the req.body information. Return a success message if the object was removed successfully OR an error message At the end of a router file you need to export it: module . exports = router ; Now the api has been completed and you can check it in a tool like postman, or inside VSCode itself with an extension we installed earlier. Create a new folder inside the express folder called requests and inside of it a file with an .http extension. For example: get.http Make sure your server is up and running with nodemon and then in the get.http file type in: GET http://loclahost:4000/api/names/ and then you can run it by right clicking on the code area and select \"Send Request\" The result of the request should now appear on the right side of the editor. Adding React At this stage I would suggest creating another branch in your git reposiotry, because we are now going to add the View. In a later class, we can then create a different branch and add other view using Angular. git checkout -b react master You will notice you are now in that branch when you look at the bottom left of the editor. Now there is already a react folder here, but if there wasn't we would now go back to our webroot folder and type in: create-react-app react Since we already have it, go into the folder and make sure everything is setup correctly. At this stage, you should still have your mongodb running, so open a new terminal by clicking on the + symbol and type in: npm install Then you can start the app by running: npm start Now you should be able to see both the express server and the react app in the browser by typing in http://localhost:4000 and http://localhost:3000 respectively. To be able to use the data from a database we need to know a little about life cycles. React has a few of them, but for this part we will only look at one. componentWillMount () What this allows us to do is do some data processing - like a fetch request - before the component mounts and then we can see the data displayed properly. A lifecycle is placed within the component under the state, but above the render function. The code for the lifecycle we need is: state = { data : [] } getAllTheNames () { return fetch ( http://localhost:4000/api/names ) . then ( resp = resp . json ()) . then ( data = this . setState ({ data : data })); } componentWillMount () { this . getAllTheNames () } Now if we copy and paste this into our App function, this won't work - because react functions are stateless. So after removing everything we don't need from our component Change this: import React from react ; import ./App.css ; function App () { return ( div className = App /div ); } export default App ; Into this: import React , { Component } from react ; import ./App.css ; class App extends Component { state = { data : [] } getAllTheNames () { return fetch ( http://localhost:4000/api/names ) . then ( resp = resp . json ()) . then ( data = this . setState ({ data : data })); } componentWillMount () { this . getAllTheNames () } render () { return ( div className = App h1 Student Names /h1 ul { this . state . data . map ( n = li { n . name } /li )} /ul /div ); } } export default App ; Now we have come full circle and see how we connect a database to a react app.","title":"Creating a Web Api using MERN"},{"location":"mern/#creating_a_web_api_using_mern","text":"","title":"Creating a Web Api using MERN"},{"location":"mern/#setup","text":"Setup a Folder into an ENV (Environment Variable) FOLDER = MERN101 Clone the following repository to get your setup curl -LOk https://github.com/to-jk11/mern101-pg/archive/master.zip unzip master.zip rm -f master.zip mv mern101-pg-master $FOLDER You should now have a folder called MERN101 (or whatever you called it and inside of there you should have the following folder structure: root/ | --- .vscode | --- express | --- mongodb | --- react | --- .gitignore","title":"Setup"},{"location":"mern/#install_extensions","text":"In the project there is an extensions.json file which has some recommended extensions for this project. To install there do the following: Open the MERN101 project in VSCODE Open the Extension tab (5 th one down) Type in @recommended in the search bar and install or enable to those extensions if they are not already. Restart vscode if you are being asked too (later versions don't require this) Keep VSCODE open - we won't be leaving it anytime soon :-)","title":"Install Extensions"},{"location":"mern/#change_your_terminal_into_bash","text":"All the commands listed below will work with Bash - but not necessarily with Powershell, therefore if you are on Windows, open up the file settings.json in the .vscode folder and uncomment the terminal line. After this you will need to trash any terminal sessions you have open to see the bash terminal.","title":"Change your terminal into Bash"},{"location":"mern/#npm_install","text":"The repository does not come with any of the remote packages installed - so let's do that first. Go into the mern folder = cd react Install node packages = npm i","title":"NPM Install"},{"location":"mern/#start_the_mongodb_server","text":"Go up one folder = cd .. Navigate into the mongodb folder = cd mongodb Start the mongod server = mongod --config mongo.conf Terminal window in VSCode is now taken up by the mongod server, so click the + symbol to open another one.","title":"Start the Mongodb server"},{"location":"mern/#viewing_your_database_files","text":"In the left bar of VSCode you should see an icon that looks like the Azure logo. (it is a triangle shaped letter A) From here you should be able to connect to the database by clicking on the \"Attached Database Accounts\" and then \"Attach Database Account...\" The Wizard will take your through the connection steps. Select MongoDB from the list and after that you won't need to change anything.","title":"Viewing your database files"},{"location":"mern/#setup_a_user_and_structure_for_your_database","text":"In a fresh bash shell (remmember that + you clicked) You can then load the setup file that you find in the mongodb folder. mongo mongo-script setup.js After this you can refresh your db connection in the azure extension and see that the db, collections and user has been created.","title":"Setup a user and structure for your database"},{"location":"mern/#setup_express","text":"To be able to view our data on a webpage, we need to setup a webserver. We do this using express and node. (The N and E of MERN) If we go back to the MVC model, then this section is setting up the Controller and the Model. Inside of our express, we are going to create a number of api endpoints and then access those later in React - which will serve as the View. In the express folder, there is a package.json file, which contains the packages that we need to install. Make sure you are in the root folder of this project. To check if you are, type in ls -la and you should see the above mentioned root directory structure. drwxr-xr-x 13 jeff_mba staff 416 5 May 19 :57 .git -rw-r--r-- 1 jeff_mba staff 49 5 May 17 :39 .gitignore drwxr-xr-x 4 jeff_mba staff 128 5 May 18 :05 .vscode drwxr-xr-x 3 jeff_mba staff 96 5 May 20 :00 express drwxr-xr-x 6 jeff_mba staff 192 5 May 18 :41 mongodb drwxr-xr-x 9 jeff_mba staff 288 5 May 17 :39 react Go into the express folder = cd express (everything in this section will be in that folder unless otherwise specified) Install the node packages = npm install The rest we need to manually setup. Now we need to setup express, as part of the recommended extensions you will have installed or enabled the express snippets extensions.","title":"Setup Express"},{"location":"mern/#setup_serverjs","text":"Next create an server.js file and use the ex4 followed by the key to give yourself an express template. You will need to make the following changes: On Line 3 add const port = 4000 - react will run on port 3000 later On Line 10 (probably) replace the console.log with this = console . log ( `Server running on port ${ port } ` ); Remove the commented line on line 13 (again probably) Test that your app runs correctly, by typing in npm start in the terminal - this will start the express server using nodemon. (use npm i -g nodemon if you haven't got this installed) Using the browser preview (by clicking on in the left tab) you should be able to navigate to localhost:4000/ and see Hello World on the screen.","title":"Setup Server.js"},{"location":"mern/#creating_our_database_models","text":"Create a folder and a file in the express folder = mkdir config touch config/keys.js Inside of the keys.js file add the following code: module . exports = { mongoURI : mongodb://admin:admin123@localhost:27017/students } Next we need to create our Model files: mkdir Models touch Models/names.js touch Models/subjects.js In these files, we create the models that we need to match our database Here is the schema for the names collection - you will need to create the schema for the subjects yourself. // Schema definition file for our colour collection data var mongoose = require ( mongoose ); var Schema = mongoose . Schema ; //create a schema description of our color document structure const namesSchema = new Schema ( { _id : Number , name : String }, { collection : names }, { versionKey : false } ); module . exports = Names = mongoose . model ( Names , namesSchema );","title":"Creating our Database Models"},{"location":"mern/#connecting_express_to_database","text":"Before we create the api, let's make a small adjustment to our server.js file Replace this code: app . get ( / , ( req , res ) = { res . send ( Hello World! ); }); With this: const mongoose = require ( mongoose ); const bodyparser = require ( body-parser ); const namesroute = require ( ./routes/api/namesroute ); const subjectsroute = require ( ./routes/api/subjectsroute ); app . use ( bodyparser . json ()); app . use ( function ( req , res , next ) { res . header ( Access-Control-Allow-Origin , * ); res . header ( Access-Control-Allow-Headers , Origin, X-Requested-With, Content-Type, Accept ); next (); }); app . use ( /api/names , namesroute ); app . use ( /api/subjects , subjectsroute ); const db = require ( ./config/keys ). mongoURI ; mongoose . connect ( db , { useNewURLParser : true }) . then ( function (){ console . log ( MongoDB connected... ); }) . catch ( function ( err ){ console . log ( err ) }); app . get ( / , ( req , res ) = { res . json ({ reply : Route for HOME path. }); }); In the abovde code, we are adding the mongoose and bodyparser middelwares. We are also setting up our api endpoints and connecting to our database. The last part for our server is to add our API routes.","title":"Connecting Express to Database"},{"location":"mern/#setting_up_our_api_crud_endpoints","text":"Still in our express folder, create a new folder called routes and then inside of that folder create another folder called api. mkdir -p express/api Inside of this folder create 2 files: touch routes/api/namesroute.js touch routes/api/subjectsroute.js Again - just like with the model - I will show you the names route and you have to create the subjects route. At the top of a route file type in: const express = require ( express ); const router = express . Router (); const names = require ( ../../models/names ); You won't need to do an npm install for this, since the router is build into express. Each of the endpoints that we cover below we add start with the following comments: //@route GET /api/names //@desc Get all Names from the DB //@access Public We need these, so we can easily identity what each of the routes do for us. Each of the route endpoints is placed after the endpoint set in the server.js file For example - when we define / we get there by typing in /api/names/ as the url. Each of the route endpoints is setup as a javascript promise inside of a javascript object.","title":"Setting up our API CRUD endpoints"},{"location":"mern/#get_methods","text":"//@route GET /api/names //@desc Get all Names from the DB //@access Public router . get ( / , function ( req , res ){ names . find () . sort ({ name : 1 }) . then ( function ( name ){ res . json ( name ); }) . catch ( function ( err ){ console . log ( err ); }) }); In the above code we do the following: Set the route Set the name of the collection use the find() method that finds all the data sort the data in ascending order present the data to us in json format OR gives us information if there is an error If we have a look at find a single piece of data, the setup is very similar: //@route GET /api/names/:names //@desc Get all Names from the DB matching the parameter //@access Public router . get ( /:name , function ( req , res ){ names . find ({ name : req . params . name }) . sort ({ name : 1 }) . then ( function ( name ){ ( name === 0 ) ? res . json ({ msg : ` ${ req . params . name } does not exist` }) : res . json ( name ); }) . catch ( function ( err ){ console . log ( err ); }) }); In the above code we do the following: Set the route Set the name of the collection use the find({name: req.params.name}) method that finds the data matching the name sort the data in ascending order present the data to us in json format OR gives us information if there is an error For the other routes, we need to deal with the object schema we created earlier:","title":"Get Methods"},{"location":"mern/#for_the_post_method","text":"For post we need to read incoming data - this is done using the req.body property. //@route POST /api/names/ //@desc Add a new Name to the DB //@access Public router . post ( / , function ( req , res ){ let newName = new Names ( req . body ); newName . save ( newName ) . then (() = { res . json ({ success : Name Added }); }) . catch ( err = { res . status ( 404 ). json ({ error : err }) }) }); In the above code we do the following: Set the route Instantiate the info from req.body to a new Names object With the new object we call the save function and pass in the object. Return a success message if the object was added successfully OR an error message","title":"For the POST Method"},{"location":"mern/#for_the_delete_method","text":"To delete a record we need to know the id. //@route DELETE /api/names/:id //@desc Delete a name from the DB by _id key //@access Public (should be secured) router . delete ( /:id , function ( req , res ){ names . findByIdAndDelete ( req . params . id ) . then ( name = { name . remove (); res . json ({ success : Name Deleted }); }) . catch ( err = { res . status ( 404 ). json ({ error : err }) }) }); In the above code we do the following: Set the route Find the record that matches the id Delete the matching record Return a success message if the object was removed successfully OR an error message","title":"For the DELETE Method"},{"location":"mern/#for_the_update_method","text":"For the update method, you will need an id - so only a single object is updated and the content from the form. //@route UPDATE /api/names/:id //@desc Update a Name from the DB by _id key //@access Public (should be secured) router.put( /:id , ( req, res) = { names .findByIdAndUpdate(req.params.id, req.body) .then(name = { name.set(req.body) res.json({ success: Name Updated }); }) .catch(err = { res.status(404).json({ error: err }) }) }); In the above code we do the following: Set the route Find the record that matches the id Call the set method and pass in the req.body information. Return a success message if the object was removed successfully OR an error message At the end of a router file you need to export it: module . exports = router ; Now the api has been completed and you can check it in a tool like postman, or inside VSCode itself with an extension we installed earlier. Create a new folder inside the express folder called requests and inside of it a file with an .http extension. For example: get.http Make sure your server is up and running with nodemon and then in the get.http file type in: GET http://loclahost:4000/api/names/ and then you can run it by right clicking on the code area and select \"Send Request\" The result of the request should now appear on the right side of the editor.","title":"For the Update Method"},{"location":"mern/#adding_react","text":"At this stage I would suggest creating another branch in your git reposiotry, because we are now going to add the View. In a later class, we can then create a different branch and add other view using Angular. git checkout -b react master You will notice you are now in that branch when you look at the bottom left of the editor. Now there is already a react folder here, but if there wasn't we would now go back to our webroot folder and type in: create-react-app react Since we already have it, go into the folder and make sure everything is setup correctly. At this stage, you should still have your mongodb running, so open a new terminal by clicking on the + symbol and type in: npm install Then you can start the app by running: npm start Now you should be able to see both the express server and the react app in the browser by typing in http://localhost:4000 and http://localhost:3000 respectively. To be able to use the data from a database we need to know a little about life cycles. React has a few of them, but for this part we will only look at one. componentWillMount () What this allows us to do is do some data processing - like a fetch request - before the component mounts and then we can see the data displayed properly. A lifecycle is placed within the component under the state, but above the render function. The code for the lifecycle we need is: state = { data : [] } getAllTheNames () { return fetch ( http://localhost:4000/api/names ) . then ( resp = resp . json ()) . then ( data = this . setState ({ data : data })); } componentWillMount () { this . getAllTheNames () } Now if we copy and paste this into our App function, this won't work - because react functions are stateless. So after removing everything we don't need from our component Change this: import React from react ; import ./App.css ; function App () { return ( div className = App /div ); } export default App ; Into this: import React , { Component } from react ; import ./App.css ; class App extends Component { state = { data : [] } getAllTheNames () { return fetch ( http://localhost:4000/api/names ) . then ( resp = resp . json ()) . then ( data = this . setState ({ data : data })); } componentWillMount () { this . getAllTheNames () } render () { return ( div className = App h1 Student Names /h1 ul { this . state . data . map ( n = li { n . name } /li )} /ul /div ); } } export default App ; Now we have come full circle and see how we connect a database to a react app.","title":"Adding React"},{"location":"package_managers/npm/","text":"NPM - Node Package Manager NPM stands for Node Package Manager and it is a way to easily get javascript based libraries and frameworks added to your project. When installing NPM packages a node_modules folder is added to your project. If you are using git, then this is something you want to add to your .gitignore file. NPM Usage NPM is a command line tool and is installed when you install nodejs. So even if you don't use Nodejs in your project, you will probably have it installed on your machine so you can use NPM. NPM has a couple of basic commands: Commands Descripion npm i This installs a package as a dependency (used for frameworks and libraries) npm i -D This installs a package as a developer's dependency (used for packaging tools and stuff not required in production) npm i -g Used if you want to install a tool globally, after this the package often runs a like a software app. examples are: create-react-app and nodemon npm start Default way to run your application, if specified in package.json npm run deploy Same as npm start , but using a custom command not listed in the npm defaults. npm init A wizard to take you through the creation of a package.json file npm init -y The wizard is skipped and a package.json file is created using default values. Package.json What is package.json? All npm packages contain a file, usually in the project root, called package.json - this file holds various metadata relevant to the project. This file is used to give information to npm that allows it to identify the project as well as handle the project's dependencies. It can also contain other metadata such as a project description, the version of the project in a particular distribution, license information and et al.","title":"NPM - Node Package Manager"},{"location":"package_managers/npm/#npm_-_node_package_manager","text":"NPM stands for Node Package Manager and it is a way to easily get javascript based libraries and frameworks added to your project. When installing NPM packages a node_modules folder is added to your project. If you are using git, then this is something you want to add to your .gitignore file.","title":"NPM - Node Package Manager"},{"location":"package_managers/npm/#npm_usage","text":"NPM is a command line tool and is installed when you install nodejs. So even if you don't use Nodejs in your project, you will probably have it installed on your machine so you can use NPM. NPM has a couple of basic commands: Commands Descripion npm i This installs a package as a dependency (used for frameworks and libraries) npm i -D This installs a package as a developer's dependency (used for packaging tools and stuff not required in production) npm i -g Used if you want to install a tool globally, after this the package often runs a like a software app. examples are: create-react-app and nodemon npm start Default way to run your application, if specified in package.json npm run deploy Same as npm start , but using a custom command not listed in the npm defaults. npm init A wizard to take you through the creation of a package.json file npm init -y The wizard is skipped and a package.json file is created using default values.","title":"NPM Usage"},{"location":"package_managers/npm/#packagejson","text":"What is package.json? All npm packages contain a file, usually in the project root, called package.json - this file holds various metadata relevant to the project. This file is used to give information to npm that allows it to identify the project as well as handle the project's dependencies. It can also contain other metadata such as a project description, the version of the project in a particular distribution, license information and et al.","title":"Package.json"},{"location":"php/01-container-setup/","text":"Setup new container IF YOU ARE USING DOCKER-TOOLBOX FOR WINDOWS For Docker Toolbox for Windows to be able to share it's files with the host machine to the container, the container MUST be placed inside the C:\\Users\\** folder. So create a folder called docker inside C:\\Users\\ your username \\ otherwise you cannot make this work. To create the docker folder do this: type in cd /c/Users/ username / create the docker folder mkdir docker go into the folder cd docker Once you have done this once, in the future you can simply go to the folder by typing in: cd /c/Users/ username /docker (THIS IS CASE SENSITIVE) IF YOU ARE USING VIRTUALBOX!!! When using Virtualbox, there are some extra settings you need to do before this works. Use the docker-toolbox terminal to stop the docker-machine - type in: docker-machine stop You can confirm that the VM has stopped by opening up the Virtualbox Window. Create a folder on your H: Drive - called docker Next open CMD prompt (not the docker toolbox terminal) Type in each of the following commands (or copy / paste them) C: `cd \"Program Files\\Oracle\\Virtualbox\" VBoxManage.exe sharedfolder add default --name \"h/docker\" --hostpath \"\\\\?\\h:\\docker\" --automount VBoxManage.exe setextradata default VBoxInternal2/SharedFoldersEnableSymlinksCreate/v-root 1 VBoxManage.exe setextradata default VBoxInternal2/SharedFoldersEnableSymlinksCreate/h/docker 1 Close the CMD window and go back to the Docker Terminal Window Start up the VM again by typing in: docker-machine stop Access the VM by typing in: docker-machine ssh default Next type in: sudo mkdir --parents /h/docker sudo mount -t vboxsf h/docker /h/docker/ exit Now you can run the curl command below from your H: Drive. For reference you can read up on it here important Stop any current containers you have going this will free up the ports that are in use: docker stop $( docker ps -a ) This won't delete them, but it will free up the ports that are used by any containers. Navigate to your code folder where you want to store you project, this could be your desktop or a designated folder. cd ~/Desktop // **REMEMBER IF YOU ARE USING DOCKER TOOLBOX FOR WINDOWS** cd /c/Users/ username /docker Set a ENV Variable temporary for the folder name FOLDER= VALUE where = the name you want your project to be Note ENV Variables, will loose their value when you close the terminal window. There is a way to recreate them, but since we don't want to have this variable permanently setup we won't do that here. Every time you want to reference our project, we can just use $FOLDER instead of the actual name. Download the docker-compose file curl -LOk https://github.com/to-jk11/php-container-kit/archive/master.zip unzip master.zip rm -f master.zip mv php-container-kit-master $FOLDER mkdir -p $FOLDER /www Go into the VALUE folder: cd $FOLDER Inside the folder there is a docker-compose.yml file. Run the docker-compose command to get your containers up and running: docker-compose up -d The www folder serves as the root folder of your website. So that is where you put your code files. You can now open the www in your favourite code editor. (for example code www ) Next you will need to install composer which you can do here: Download for windows Composer for Windows Download for Mac Copy each of these lines into your terminal php -r copy( https://getcomposer.org/installer , composer-setup.php ); php -r if (hash_file( sha384 , composer-setup.php ) === 48e3236262b34d30969dca3c37281b3b4bbe3221bda826ac6a9a62d6444cdb0dcd0615698a5cbe587c3f0fe57a54d8f5 ) { echo Installer verified ; } else { echo Installer corrupt ; unlink( composer-setup.php ); } echo PHP_EOL; php composer-setup.php php -r unlink( composer-setup.php ); Note The container has been setup with the apache2 rewrite module enabled. This will be important when we start using MVC.","title":"Setup new container"},{"location":"php/01-container-setup/#setup_new_container","text":"IF YOU ARE USING DOCKER-TOOLBOX FOR WINDOWS For Docker Toolbox for Windows to be able to share it's files with the host machine to the container, the container MUST be placed inside the C:\\Users\\** folder. So create a folder called docker inside C:\\Users\\ your username \\ otherwise you cannot make this work. To create the docker folder do this: type in cd /c/Users/ username / create the docker folder mkdir docker go into the folder cd docker Once you have done this once, in the future you can simply go to the folder by typing in: cd /c/Users/ username /docker (THIS IS CASE SENSITIVE) IF YOU ARE USING VIRTUALBOX!!! When using Virtualbox, there are some extra settings you need to do before this works. Use the docker-toolbox terminal to stop the docker-machine - type in: docker-machine stop You can confirm that the VM has stopped by opening up the Virtualbox Window. Create a folder on your H: Drive - called docker Next open CMD prompt (not the docker toolbox terminal) Type in each of the following commands (or copy / paste them) C: `cd \"Program Files\\Oracle\\Virtualbox\" VBoxManage.exe sharedfolder add default --name \"h/docker\" --hostpath \"\\\\?\\h:\\docker\" --automount VBoxManage.exe setextradata default VBoxInternal2/SharedFoldersEnableSymlinksCreate/v-root 1 VBoxManage.exe setextradata default VBoxInternal2/SharedFoldersEnableSymlinksCreate/h/docker 1 Close the CMD window and go back to the Docker Terminal Window Start up the VM again by typing in: docker-machine stop Access the VM by typing in: docker-machine ssh default Next type in: sudo mkdir --parents /h/docker sudo mount -t vboxsf h/docker /h/docker/ exit Now you can run the curl command below from your H: Drive. For reference you can read up on it here important Stop any current containers you have going this will free up the ports that are in use: docker stop $( docker ps -a ) This won't delete them, but it will free up the ports that are used by any containers. Navigate to your code folder where you want to store you project, this could be your desktop or a designated folder. cd ~/Desktop // **REMEMBER IF YOU ARE USING DOCKER TOOLBOX FOR WINDOWS** cd /c/Users/ username /docker Set a ENV Variable temporary for the folder name FOLDER= VALUE where = the name you want your project to be Note ENV Variables, will loose their value when you close the terminal window. There is a way to recreate them, but since we don't want to have this variable permanently setup we won't do that here. Every time you want to reference our project, we can just use $FOLDER instead of the actual name. Download the docker-compose file curl -LOk https://github.com/to-jk11/php-container-kit/archive/master.zip unzip master.zip rm -f master.zip mv php-container-kit-master $FOLDER mkdir -p $FOLDER /www Go into the VALUE folder: cd $FOLDER Inside the folder there is a docker-compose.yml file. Run the docker-compose command to get your containers up and running: docker-compose up -d The www folder serves as the root folder of your website. So that is where you put your code files. You can now open the www in your favourite code editor. (for example code www ) Next you will need to install composer which you can do here: Download for windows Composer for Windows Download for Mac Copy each of these lines into your terminal php -r copy( https://getcomposer.org/installer , composer-setup.php ); php -r if (hash_file( sha384 , composer-setup.php ) === 48e3236262b34d30969dca3c37281b3b4bbe3221bda826ac6a9a62d6444cdb0dcd0615698a5cbe587c3f0fe57a54d8f5 ) { echo Installer verified ; } else { echo Installer corrupt ; unlink( composer-setup.php ); } echo PHP_EOL; php composer-setup.php php -r unlink( composer-setup.php ); Note The container has been setup with the apache2 rewrite module enabled. This will be important when we start using MVC.","title":"Setup new container"},{"location":"php/mvc-framework/01-index/","text":"Basic MVC Framework This MVC framework is written in PHP and is based on an opensource framework by Brad Traversy Quick use: You can use this framework in 2 ways: Full PHP MVC = Views are written in here and saved in the app/views folder. Partial PHP MVC (Only Model and Controller) = The controller has api endpoints which output JSON data and the Views are written in another language. Could even be hosted in another container or server. This would purely serve as the backend. Requirements\" tab=\"macoS This setup uses php composer and that can be installed in the following way: macoS # Install homebrew (https://brew.sh) (if you haven t already) /usr/bin/ruby -e $( curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install ) # Install composer brew install composer windows # Install chocolatey (https://chocolatey.org) (if you haven t already) # Run this command in the CMD.exe (Command Prompt) with administrator priviledges @ %SystemRoot%\\System32\\WindowsPowerShell\\v1.0\\powershell.exe -NoProfile -InputFormat None -ExecutionPolicy Bypass -Command iex ((New-Object System.Net.WebClient).DownloadString( https://chocolatey.org/install.ps1 )) SET PATH=%PATH%;%ALLUSERSPROFILE%\\chocolatey\\bin # OR # Run this command in Powershell with administrator priviledges Set-ExecutionPolicy Bypass -Scope Process -Force; iex ((New-Object System.Net.WebClient).DownloadString( https://chocolatey.org/install.ps1 )) # Install composer chocolatey install composer -y linux (using apt-get) # linux already comes with a package manager (apt-get), so just type in the following sudo apt update sudo apt install curl php-cli php-mbstring git unzip cd ~ curl -sS https://getcomposer.org/installer -o composer-setup.php sudo php composer-setup.php --install-dir = /usr/local/bin --filename = composer linux (using homebrew) # install homebrew in your homedirectory sh -c $( curl -fsSL https://raw.githubusercontent.com/Linuxbrew/install/master/install.sh ) test -d ~/.linuxbrew eval $( ~/.linuxbrew/bin/brew shellenv ) test -d /home/linuxbrew/.linuxbrew eval $( /home/linuxbrew/.linuxbrew/bin/brew shellenv ) test -r ~/.bash_profile echo eval \\$( $( brew --prefix ) /bin/brew shellenv) ~/.bash_profile echo eval \\$( $( brew --prefix ) /bin/brew shellenv) ~/.profile # Install composer brew install composer Tip After you install 1 or more programs in the command line, it always pays to restart your terminal to refresh all the PATH variables Docker containers This repository does not include the docker-compose file to setup a LAMP stack. You can find those instructions here Note that the credentials that are stored in this repository for the LAMP stack refer to the docker setup in that link. However you are free to change those to what you require.","title":"Basic MVC Framework"},{"location":"php/mvc-framework/01-index/#basic_mvc_framework","text":"This MVC framework is written in PHP and is based on an opensource framework by Brad Traversy","title":"Basic MVC Framework"},{"location":"php/mvc-framework/01-index/#quick_use","text":"You can use this framework in 2 ways: Full PHP MVC = Views are written in here and saved in the app/views folder. Partial PHP MVC (Only Model and Controller) = The controller has api endpoints which output JSON data and the Views are written in another language. Could even be hosted in another container or server. This would purely serve as the backend. Requirements\" tab=\"macoS This setup uses php composer and that can be installed in the following way: macoS # Install homebrew (https://brew.sh) (if you haven t already) /usr/bin/ruby -e $( curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install ) # Install composer brew install composer windows # Install chocolatey (https://chocolatey.org) (if you haven t already) # Run this command in the CMD.exe (Command Prompt) with administrator priviledges @ %SystemRoot%\\System32\\WindowsPowerShell\\v1.0\\powershell.exe -NoProfile -InputFormat None -ExecutionPolicy Bypass -Command iex ((New-Object System.Net.WebClient).DownloadString( https://chocolatey.org/install.ps1 )) SET PATH=%PATH%;%ALLUSERSPROFILE%\\chocolatey\\bin # OR # Run this command in Powershell with administrator priviledges Set-ExecutionPolicy Bypass -Scope Process -Force; iex ((New-Object System.Net.WebClient).DownloadString( https://chocolatey.org/install.ps1 )) # Install composer chocolatey install composer -y linux (using apt-get) # linux already comes with a package manager (apt-get), so just type in the following sudo apt update sudo apt install curl php-cli php-mbstring git unzip cd ~ curl -sS https://getcomposer.org/installer -o composer-setup.php sudo php composer-setup.php --install-dir = /usr/local/bin --filename = composer linux (using homebrew) # install homebrew in your homedirectory sh -c $( curl -fsSL https://raw.githubusercontent.com/Linuxbrew/install/master/install.sh ) test -d ~/.linuxbrew eval $( ~/.linuxbrew/bin/brew shellenv ) test -d /home/linuxbrew/.linuxbrew eval $( /home/linuxbrew/.linuxbrew/bin/brew shellenv ) test -r ~/.bash_profile echo eval \\$( $( brew --prefix ) /bin/brew shellenv) ~/.bash_profile echo eval \\$( $( brew --prefix ) /bin/brew shellenv) ~/.profile # Install composer brew install composer Tip After you install 1 or more programs in the command line, it always pays to restart your terminal to refresh all the PATH variables","title":"Quick use:"},{"location":"php/mvc-framework/01-index/#docker_containers","text":"This repository does not include the docker-compose file to setup a LAMP stack. You can find those instructions here Note that the credentials that are stored in this repository for the LAMP stack refer to the docker setup in that link. However you are free to change those to what you require.","title":"Docker containers"},{"location":"php/mvc-framework/02-setup/","text":"Setup MVC Project What you need This repository should be loaded in the www folder if you are using the https://github.com/to-jk11/php-container-kit/ repository Download the following files into the www container Get the MVC Framework curl -LOk https://github.com/to-jk11/php-mvc-kit/archive/master.zip unzip master.zip cd php-mvc-kit-master/ find . -maxdepth 1 -exec mv {} .. \\; cd .. rm -rf php-mvc-kit-master rm -rf master.zip A lot happens in the command above, so if you want to know what it does, click on the hint below. If you want to know what happens First we download the repostory that contains all the base code as a zip file curl -LOk https://github.com/to-jk11/php-mvc-kit/archive/master.zip Next we unzip the master.zip file, which gives us the php-mvc-kit-master folder cd php-mvc-kit-master Then we move all of the files into the parent folder: `find . -maxdepth 1 -exec mv {} .. \\;` Ignore the message that says: mv: cannot move .' to ../.': Device or resource busy Last we go back to the parent folder and remove the php-mvc-kit-master folder and the master.zip file cd .. rm -rf php-mvc-kit-master rm -rf master.zip Once the framework has been downloaded type in composer update and wait while some plugins are installed. NOTE: use php composer.phar update if you are on a mac. Setup your git repository Setup Git Next you will need to create your git repository so you can save your work: git init Add the remote repository link // If you are using https and have a public repository (uses port 443) git remote add origin https://url-to-your-repo // If you are using https and have a private repository (uses port 443) git remote add origin https://token@username:url-to-your-repo // If you are using ssh (uses port 22) git remote add origin git@github.com:username/reponame The link \"https://url-to-your-repo\" is the link to your github repository Now you can go to http://localhost:8000 (docker for (your OS)) or http://192.168.99.100:8000 (docker toolbox in combination with VirtualBox) and you will see the following screen: Note When using Docker Toolbox for windows, the URL will be http://192.168.99.100:8000","title":"Setup MVC Project"},{"location":"php/mvc-framework/02-setup/#setup_mvc_project","text":"What you need This repository should be loaded in the www folder if you are using the https://github.com/to-jk11/php-container-kit/ repository Download the following files into the www container Get the MVC Framework curl -LOk https://github.com/to-jk11/php-mvc-kit/archive/master.zip unzip master.zip cd php-mvc-kit-master/ find . -maxdepth 1 -exec mv {} .. \\; cd .. rm -rf php-mvc-kit-master rm -rf master.zip A lot happens in the command above, so if you want to know what it does, click on the hint below. If you want to know what happens First we download the repostory that contains all the base code as a zip file curl -LOk https://github.com/to-jk11/php-mvc-kit/archive/master.zip Next we unzip the master.zip file, which gives us the php-mvc-kit-master folder cd php-mvc-kit-master Then we move all of the files into the parent folder: `find . -maxdepth 1 -exec mv {} .. \\;` Ignore the message that says: mv: cannot move .' to ../.': Device or resource busy Last we go back to the parent folder and remove the php-mvc-kit-master folder and the master.zip file cd .. rm -rf php-mvc-kit-master rm -rf master.zip Once the framework has been downloaded type in composer update and wait while some plugins are installed. NOTE: use php composer.phar update if you are on a mac.","title":"Setup MVC Project"},{"location":"php/mvc-framework/02-setup/#setup_your_git_repository","text":"Setup Git Next you will need to create your git repository so you can save your work: git init Add the remote repository link // If you are using https and have a public repository (uses port 443) git remote add origin https://url-to-your-repo // If you are using https and have a private repository (uses port 443) git remote add origin https://token@username:url-to-your-repo // If you are using ssh (uses port 22) git remote add origin git@github.com:username/reponame The link \"https://url-to-your-repo\" is the link to your github repository Now you can go to http://localhost:8000 (docker for (your OS)) or http://192.168.99.100:8000 (docker toolbox in combination with VirtualBox) and you will see the following screen: Note When using Docker Toolbox for windows, the URL will be http://192.168.99.100:8000","title":"Setup your git repository"},{"location":"php/mvc-framework/03-how-it-works/","text":"How to setup MVC Using this framework, setting up MVC is a pretty easy process. Let's have a look at the folder structure: The main folders to focus on are: Foldername Purpose app backend files (all the php stuff) public frontend files (css, images, javascript etc) We will get to both of those later on Foldername Purpose rest Used to do some api testing, we can ignore this for now. sql Used as a place where you can save your mysql files. The file (part1.sql) that is in there is used for the demo projects. The files in the root folder are used as follows: Filename Purpose .env This is used to read your DB credentials and other info that needs to be secure .gitignore Ignore all the setup files that can be run remotely .htaccess There to route all the controller paths composer.json Install php composer packages, we only use this for env files for now env.example an example for when the .env file is ignored, which it should be readme.md default readme file Public Folder In the public folder we have 2 files at the base: .htaccess - used for routing of url paths index.php - used as a base, but not edited The index.php contains very little php: ?php include ( ../app/bootstrap.php ); $init = new Core (); ? Core is a class which is defined in the app/libraries folder. bootstrap.php is a file that sets up a number of php files we want to import, but we don't want to expose the paths of those files to the public. The other folders are just placeholders for any assets that are needed in the project. To link to any of those files we do need to use some special (sort of) php syntax, but we will get to that later. App Folder The app folder is where all the magic happens. It is also the folder we hide from the public, because all our server side code is there. Let's go through the folder / file structure Here you will see bootstrap.php . If you have a look at that file, you will just see that it imports a bunch of other files. The helper folder contains some helper files, we will reference to them later. The libraries folder contains the foundtion of the framework so look, but don't touch The models , views and controllers folder carry the respective files to make up the different webpages. Which we talk about in the next section.","title":"How to setup MVC"},{"location":"php/mvc-framework/03-how-it-works/#how_to_setup_mvc","text":"Using this framework, setting up MVC is a pretty easy process. Let's have a look at the folder structure: The main folders to focus on are: Foldername Purpose app backend files (all the php stuff) public frontend files (css, images, javascript etc) We will get to both of those later on Foldername Purpose rest Used to do some api testing, we can ignore this for now. sql Used as a place where you can save your mysql files. The file (part1.sql) that is in there is used for the demo projects. The files in the root folder are used as follows: Filename Purpose .env This is used to read your DB credentials and other info that needs to be secure .gitignore Ignore all the setup files that can be run remotely .htaccess There to route all the controller paths composer.json Install php composer packages, we only use this for env files for now env.example an example for when the .env file is ignored, which it should be readme.md default readme file","title":"How to setup MVC"},{"location":"php/mvc-framework/03-how-it-works/#public_folder","text":"In the public folder we have 2 files at the base: .htaccess - used for routing of url paths index.php - used as a base, but not edited The index.php contains very little php: ?php include ( ../app/bootstrap.php ); $init = new Core (); ? Core is a class which is defined in the app/libraries folder. bootstrap.php is a file that sets up a number of php files we want to import, but we don't want to expose the paths of those files to the public. The other folders are just placeholders for any assets that are needed in the project. To link to any of those files we do need to use some special (sort of) php syntax, but we will get to that later.","title":"Public Folder"},{"location":"php/mvc-framework/03-how-it-works/#app_folder","text":"The app folder is where all the magic happens. It is also the folder we hide from the public, because all our server side code is there. Let's go through the folder / file structure Here you will see bootstrap.php . If you have a look at that file, you will just see that it imports a bunch of other files. The helper folder contains some helper files, we will reference to them later. The libraries folder contains the foundtion of the framework so look, but don't touch The models , views and controllers folder carry the respective files to make up the different webpages. Which we talk about in the next section.","title":"App Folder"},{"location":"php/mvc-framework/04-mvc/","text":"APP : Models - Views - Controllers To know what we are working with, let's define what each of these files do. As you can see in the image above, the user uses the a website, by navigating to it. Once they are on that website, the different pieces come together. The Controller is in a way the glue to the process and so a couple of things need to be remembered. The controller communicates to the model The controller communicates to the view The model NEVER communicates to the view. Whatever data the model has, is send to the controller Whatever view there is to display the data is selected by the controller. So by those rules that are shown above, the starting point for any page would be the controller. THE URL Format When you look at a url for a website you will see the following format: The default controller for this framework is called Pages The default for index for this framework is called Index There is no default value for the parameter, since it only applies when you need a specific record for something. Now there are 2 ways you can set this up: You either create a tonne of controllers and give them each a single action or - and this is the way we will do it - you create a single controller for each function and give them each the appropriate methods in relation to the CRUD acronym. So each Controller will get at least a single actions with a maximum or 5 actions. The Controller The format of a controller looks something like this to begin with: A basic controller ?php include(APPROOT . /helper/helperfunctions.php ); class Pages extends Controller { public function __construct() { $this- people = $this- model( People ); } public function index() { // Links to model $people = $this- people- getAllPeople(); $title = $this- people- title(); $data = []; // Send data to View $this- view( pages/index , $data = []); } } ? These are not auto-generated, but you can just copy this code and modify it to what you need. Let's break it up into parts: Import the helper functions Import the helper functions so you can manipulate the URL include(APPROOT . /helper/helperfunctions.php ); Create the contoller class Create the class - this name has to be unique within your project and the file in which it is created must have the same name. The extends keyword means we are inheriting from the Controller class All the other content goes inside of it. class Pages extends Controller { ... } The constructor - setting the model In the class constructor we set the name of the model(s) we need to interact with. If you don't need a model, because your data is static - then you can omit this. You can also specify multiple models inside of the one controller, but we will look at that later on. The name of the model MUST BE the same name as the model file name as it looks for the file name. The Action The actions are part of the URL and since index is the default action, it will be needed for setting up controller only URLs. In the first part we setup all the data we need to get from our model(s), this are basically functions that request data from the database and save the result (an array) into a variable. These variables can hold anything - it doesn't have to be a function. The first part of the view() method is the link to the folder inside of the views folder and then the filename. The file name is the name of actual file in the views folder and has nothing to do with the name of the endpoint. The files may also be called template1, template2 etc. public function index() { // Links to model $people = $this- people- getAllPeople(); $title = $this- people- title(); $data = []; // Send data to View $this- view( pages/index , $data = []); } The $data array (which must be included) is used to pass in all the variables you create to the view, so you may end up with something like $this- view( pages/index , $data = [$people, $title]); or just an empty array, which is passed down by default. The Model In the models folder, we have all our models. A model is the part that queries, sends and receives the data from the database. A model is usually closely associated with a controller, as far as the name goes, but: It cannot be the same name - using an underscore in the name is enough. It should be descriptive of what you type of data you want, so it is easier to get to later. The format of a model looks something like this to begin with: A basic model class People { private $db; public function __construct() { $this- db = new Database; } public function title() { return Show All People ; } public function getAllPeople() { $this- db- query( SELECT * FROM tbl_people ); return $this- db- resultSet(); } } Again these are not auto-generated, but you can just copy this code and modify it to what you need. Let's break it up into parts: The model class The class contains all of the methods - it doesn't inherit from anyting. class People { ... } Link to Database The model is the part that communicates to the database, so it needs to setup a new instance of the object. The queries Below you will see 2 queries, one returns a string and the second one does a query to a database. public function title() { return Show All People ; } public function getAllPeople() { $this- db- query( SELECT * FROM tbl_people ); return $this- db- resultSet(); } Query with a parameter Queries can be as complex as you require them to be, but and any parameters are binded into the query. They are not directly hard coded into it. For each paramter for a query query, you need to pass in the parameter as a php variable, since you do not know what the value will be at development time. Since we don't know the value, we need to sanitize these variables and we that with the bind() function. As you can see the parameter in the query is identified with a : and in the binding function it is mapped to the variable name. When doing a Select query, we then return the result as per normal, which gives an array - even if the array only has a single item in it. public function getSinglePerson($id) { $this- db- query( SELECT * FROM tbl_people WHERE ID = :id ); $this- db- bind( :id , $id); return $this- db- resultSet(); } INSERT / UPDATE / DELETE with a parameter For the C UD and type queries, we need to pass in paramters as and they work exactly the same public function addPerson($fn, $ln, $dob) { $this- db- query( INSERT INTO tbl_people (FNAME, LNAME, DOB) VALUES (:fn, :ln, :dob) ); $this- db- bind( :fn , $fn); $this- db- bind( :ln , $ln); $this- db- bind( :dob , $dob); if($this- db- execute()) { return true; } else { return false; } } As you can see we pass in 3 parameters and sanitize each of them. At the end, we check if the database was successfully changed by returning a simple true / false boolean. The View In the views folder we have all the templates. Now each of the view templates can be used multiple times and have a different way of processing the data coming in. TIP = Example You may have a single template that has 2 columns, but how the data comes into those columns is different, therefore you need multiple versions of that one template. HINT = Use the controllers as folders To make it easier to find the templates to use for each controller, create a folder that has the name of the controller and put the template files that are needed for each controller in there. You will need to the path to the view file in the controller: $this- view( folder_name/view_template , $data = []); The view file, although it ends with a .php extension, most of it is HTML. The format of a model looks something like this to begin with: Format of View ?php include(APPROOT . /views/includes/header.php ); ? div class= row /div ?php include(APPROOT . /views/includes/footer.php ); ? The class=\"row\" is a reference to using bootstrap, but it could be anything. You will notice there are 2 files, a header.php and a footer.php file. I tend to put them in the a folder called includes which you can see from the path that is used. In the header.php file we include everything from the top html tag to the where the commonality of each page ends. So a header for a page could look like this: The footer.php file includes everything from where the first tag of a view ends and the common footer for each page starts. So a footer for a page could look like this","title":"APP : Models - Views - Controllers"},{"location":"php/mvc-framework/04-mvc/#app_models_-_views_-_controllers","text":"To know what we are working with, let's define what each of these files do. As you can see in the image above, the user uses the a website, by navigating to it. Once they are on that website, the different pieces come together. The Controller is in a way the glue to the process and so a couple of things need to be remembered. The controller communicates to the model The controller communicates to the view The model NEVER communicates to the view. Whatever data the model has, is send to the controller Whatever view there is to display the data is selected by the controller. So by those rules that are shown above, the starting point for any page would be the controller.","title":"APP : Models - Views - Controllers"},{"location":"php/mvc-framework/04-mvc/#the_url_format","text":"When you look at a url for a website you will see the following format: The default controller for this framework is called Pages The default for index for this framework is called Index There is no default value for the parameter, since it only applies when you need a specific record for something. Now there are 2 ways you can set this up: You either create a tonne of controllers and give them each a single action or - and this is the way we will do it - you create a single controller for each function and give them each the appropriate methods in relation to the CRUD acronym. So each Controller will get at least a single actions with a maximum or 5 actions.","title":"THE URL Format"},{"location":"php/mvc-framework/04-mvc/#the_controller","text":"The format of a controller looks something like this to begin with: A basic controller ?php include(APPROOT . /helper/helperfunctions.php ); class Pages extends Controller { public function __construct() { $this- people = $this- model( People ); } public function index() { // Links to model $people = $this- people- getAllPeople(); $title = $this- people- title(); $data = []; // Send data to View $this- view( pages/index , $data = []); } } ? These are not auto-generated, but you can just copy this code and modify it to what you need. Let's break it up into parts: Import the helper functions Import the helper functions so you can manipulate the URL include(APPROOT . /helper/helperfunctions.php ); Create the contoller class Create the class - this name has to be unique within your project and the file in which it is created must have the same name. The extends keyword means we are inheriting from the Controller class All the other content goes inside of it. class Pages extends Controller { ... } The constructor - setting the model In the class constructor we set the name of the model(s) we need to interact with. If you don't need a model, because your data is static - then you can omit this. You can also specify multiple models inside of the one controller, but we will look at that later on. The name of the model MUST BE the same name as the model file name as it looks for the file name. The Action The actions are part of the URL and since index is the default action, it will be needed for setting up controller only URLs. In the first part we setup all the data we need to get from our model(s), this are basically functions that request data from the database and save the result (an array) into a variable. These variables can hold anything - it doesn't have to be a function. The first part of the view() method is the link to the folder inside of the views folder and then the filename. The file name is the name of actual file in the views folder and has nothing to do with the name of the endpoint. The files may also be called template1, template2 etc. public function index() { // Links to model $people = $this- people- getAllPeople(); $title = $this- people- title(); $data = []; // Send data to View $this- view( pages/index , $data = []); } The $data array (which must be included) is used to pass in all the variables you create to the view, so you may end up with something like $this- view( pages/index , $data = [$people, $title]); or just an empty array, which is passed down by default.","title":"The Controller"},{"location":"php/mvc-framework/04-mvc/#the_model","text":"In the models folder, we have all our models. A model is the part that queries, sends and receives the data from the database. A model is usually closely associated with a controller, as far as the name goes, but: It cannot be the same name - using an underscore in the name is enough. It should be descriptive of what you type of data you want, so it is easier to get to later. The format of a model looks something like this to begin with: A basic model class People { private $db; public function __construct() { $this- db = new Database; } public function title() { return Show All People ; } public function getAllPeople() { $this- db- query( SELECT * FROM tbl_people ); return $this- db- resultSet(); } } Again these are not auto-generated, but you can just copy this code and modify it to what you need. Let's break it up into parts: The model class The class contains all of the methods - it doesn't inherit from anyting. class People { ... } Link to Database The model is the part that communicates to the database, so it needs to setup a new instance of the object. The queries Below you will see 2 queries, one returns a string and the second one does a query to a database. public function title() { return Show All People ; } public function getAllPeople() { $this- db- query( SELECT * FROM tbl_people ); return $this- db- resultSet(); } Query with a parameter Queries can be as complex as you require them to be, but and any parameters are binded into the query. They are not directly hard coded into it. For each paramter for a query query, you need to pass in the parameter as a php variable, since you do not know what the value will be at development time. Since we don't know the value, we need to sanitize these variables and we that with the bind() function. As you can see the parameter in the query is identified with a : and in the binding function it is mapped to the variable name. When doing a Select query, we then return the result as per normal, which gives an array - even if the array only has a single item in it. public function getSinglePerson($id) { $this- db- query( SELECT * FROM tbl_people WHERE ID = :id ); $this- db- bind( :id , $id); return $this- db- resultSet(); } INSERT / UPDATE / DELETE with a parameter For the C UD and type queries, we need to pass in paramters as and they work exactly the same public function addPerson($fn, $ln, $dob) { $this- db- query( INSERT INTO tbl_people (FNAME, LNAME, DOB) VALUES (:fn, :ln, :dob) ); $this- db- bind( :fn , $fn); $this- db- bind( :ln , $ln); $this- db- bind( :dob , $dob); if($this- db- execute()) { return true; } else { return false; } } As you can see we pass in 3 parameters and sanitize each of them. At the end, we check if the database was successfully changed by returning a simple true / false boolean.","title":"The Model"},{"location":"php/mvc-framework/04-mvc/#the_view","text":"In the views folder we have all the templates. Now each of the view templates can be used multiple times and have a different way of processing the data coming in. TIP = Example You may have a single template that has 2 columns, but how the data comes into those columns is different, therefore you need multiple versions of that one template. HINT = Use the controllers as folders To make it easier to find the templates to use for each controller, create a folder that has the name of the controller and put the template files that are needed for each controller in there. You will need to the path to the view file in the controller: $this- view( folder_name/view_template , $data = []); The view file, although it ends with a .php extension, most of it is HTML. The format of a model looks something like this to begin with: Format of View ?php include(APPROOT . /views/includes/header.php ); ? div class= row /div ?php include(APPROOT . /views/includes/footer.php ); ? The class=\"row\" is a reference to using bootstrap, but it could be anything. You will notice there are 2 files, a header.php and a footer.php file. I tend to put them in the a folder called includes which you can see from the path that is used. In the header.php file we include everything from the top html tag to the where the commonality of each page ends. So a header for a page could look like this: The footer.php file includes everything from where the first tag of a view ends and the common footer for each page starts. So a footer for a page could look like this","title":"The View"},{"location":"php/mvc-framework/05-exercise-1/","text":"Creating your first MVC Project In this exercise you are going to create your first MVC project. It will include a SQL file, so you don't need to write the code for that. What you need For this exercise I will assume you are working with the following tools: VSCODE Docker (toolbox or native) Web Browser (Chrome) Git (bash or on a native terminal) We will make use of the following VSCode Extensions You can install these by typing in code --install-extension followed by the name after the colon listed below MySQL: formulahendry.vscode-mysql Docker: peterjausovec.vscode-docker Docker-Compose: p1c2u.docker-compose Browser Preview: auchenberg.vscode-browser-preview You will also need to be familiar with the documentation in this section. Part 1 - Setup Docker Container Part 2 - Setup MVC Framework Part 3 - Folder Structure Part 4 - How MVC Works Let's get started! Setting up your project Create a project named MVCEX01 Once you have that in place, the outcome should be that you have a folder called MVCEX01 and in the www should be the app and public folder structure from the second curl command. Make sure you have the .env file loaded correctly, so that you see the following text on your screen: Model does not exists At this point you should also have a git repository setup and made your first commit and have it pushed to github. The workflow above is standard for every project when using frameworks. So if this something that takes you a lot of time, then keep doing it until it becomes part of your project workflow. Hint In your www folder there is a folder called .demo and this folder has complete working files that make up MVC scenarios. Creating a controller Create a controller file called People.php and place it in the Controllers folder Add the basic layout for the controller into that folder. ?php include(APPROOT . /helper/helperfunctions.php ); class People extends Controller { } ? The APPROOT is a constant that points the webserver to the app folder. You can see its definition in the startup.php file located in the helper folder. As you may remember from the Controller explaination, the People controller inherits some content from the Controller class In the People controller file we are going to add an action. Actions are normal functions and they hold the content that comes in from the model and send the content to the view. Let's create a simple Index action to begin with: public function index() { return $this- view( people/view1 , $data = []); } If you now navigate to http://localhost:8000/People (or http://192.168.99.100:8000/People ) your webpage, you should see the message: View does not exists (For the attention to detail people, I am running my server temporarily on port 9000, but everything else works the same) In the views folder create a folder called people and inside of that create a file called called view1.php . In the view1.php file, just write h1 Hello View1 /h1 and save the file. After refreshing the page you should now see this: Creating the model Inside of the class need to point to a model, since we are going to be using a database. So for now, just create a file called _People.php (Note the underscore) inside of the Models folder. In the People Controller add this piece of code, above the index action. Class contructor public function __construct() { $this- people = $this- model( _People ); } At this stage, if you refresh the page, you will see that you have an error that says it can't find the model class. In the _People.php file, add the base code for a model which is: Base Model ?php class _People { public function title() { return View1 title loaded from a model ; } } ? Warning Your class name MUST BE the same name as the file name, as the system looks for both. In the model above you can see that we have created a function for the title. Let's add that to our controller. Adding the model to the controller Update the index action to look like this: Updated index action public function index() { $title = $this- people- title(); $data = [ title = $title ]; return $this- view( people/view1 , $data); } Next we need to reference that $title variable in the view. Displaying the model in the view Open up the view1.php and replace the current code with this code: Loading the view ?php echo h1 .$data[ title ]. /h1 ; In the code above we type in our HTML code - HTML code is never typed in the model, but only in the view. The fullstop is the php character to concatenate strings. As you can see we are adding the $data associative array (which is also called a dictionary) and use the key that was set in the controller to access the data. In this case $data['title'] is just a string, so it is pretty easy. You should now see this: In exercise 2 we will add data from the database to the view.","title":"Creating your first MVC Project"},{"location":"php/mvc-framework/05-exercise-1/#creating_your_first_mvc_project","text":"In this exercise you are going to create your first MVC project. It will include a SQL file, so you don't need to write the code for that. What you need For this exercise I will assume you are working with the following tools: VSCODE Docker (toolbox or native) Web Browser (Chrome) Git (bash or on a native terminal) We will make use of the following VSCode Extensions You can install these by typing in code --install-extension followed by the name after the colon listed below MySQL: formulahendry.vscode-mysql Docker: peterjausovec.vscode-docker Docker-Compose: p1c2u.docker-compose Browser Preview: auchenberg.vscode-browser-preview You will also need to be familiar with the documentation in this section. Part 1 - Setup Docker Container Part 2 - Setup MVC Framework Part 3 - Folder Structure Part 4 - How MVC Works Let's get started!","title":"Creating your first MVC Project"},{"location":"php/mvc-framework/05-exercise-1/#setting_up_your_project","text":"Create a project named MVCEX01 Once you have that in place, the outcome should be that you have a folder called MVCEX01 and in the www should be the app and public folder structure from the second curl command. Make sure you have the .env file loaded correctly, so that you see the following text on your screen: Model does not exists At this point you should also have a git repository setup and made your first commit and have it pushed to github. The workflow above is standard for every project when using frameworks. So if this something that takes you a lot of time, then keep doing it until it becomes part of your project workflow. Hint In your www folder there is a folder called .demo and this folder has complete working files that make up MVC scenarios.","title":"Setting up your project"},{"location":"php/mvc-framework/05-exercise-1/#creating_a_controller","text":"Create a controller file called People.php and place it in the Controllers folder Add the basic layout for the controller into that folder. ?php include(APPROOT . /helper/helperfunctions.php ); class People extends Controller { } ? The APPROOT is a constant that points the webserver to the app folder. You can see its definition in the startup.php file located in the helper folder. As you may remember from the Controller explaination, the People controller inherits some content from the Controller class In the People controller file we are going to add an action. Actions are normal functions and they hold the content that comes in from the model and send the content to the view. Let's create a simple Index action to begin with: public function index() { return $this- view( people/view1 , $data = []); } If you now navigate to http://localhost:8000/People (or http://192.168.99.100:8000/People ) your webpage, you should see the message: View does not exists (For the attention to detail people, I am running my server temporarily on port 9000, but everything else works the same) In the views folder create a folder called people and inside of that create a file called called view1.php . In the view1.php file, just write h1 Hello View1 /h1 and save the file. After refreshing the page you should now see this:","title":"Creating a controller"},{"location":"php/mvc-framework/05-exercise-1/#creating_the_model","text":"Inside of the class need to point to a model, since we are going to be using a database. So for now, just create a file called _People.php (Note the underscore) inside of the Models folder. In the People Controller add this piece of code, above the index action. Class contructor public function __construct() { $this- people = $this- model( _People ); } At this stage, if you refresh the page, you will see that you have an error that says it can't find the model class. In the _People.php file, add the base code for a model which is: Base Model ?php class _People { public function title() { return View1 title loaded from a model ; } } ? Warning Your class name MUST BE the same name as the file name, as the system looks for both. In the model above you can see that we have created a function for the title. Let's add that to our controller.","title":"Creating the model"},{"location":"php/mvc-framework/05-exercise-1/#adding_the_model_to_the_controller","text":"Update the index action to look like this: Updated index action public function index() { $title = $this- people- title(); $data = [ title = $title ]; return $this- view( people/view1 , $data); } Next we need to reference that $title variable in the view.","title":"Adding the model to the controller"},{"location":"php/mvc-framework/05-exercise-1/#displaying_the_model_in_the_view","text":"Open up the view1.php and replace the current code with this code: Loading the view ?php echo h1 .$data[ title ]. /h1 ; In the code above we type in our HTML code - HTML code is never typed in the model, but only in the view. The fullstop is the php character to concatenate strings. As you can see we are adding the $data associative array (which is also called a dictionary) and use the key that was set in the controller to access the data. In this case $data['title'] is just a string, so it is pretty easy. You should now see this: In exercise 2 we will add data from the database to the view.","title":"Displaying the model in the view"},{"location":"php/mvc-framework/06-exercise-2/","text":"Loading your database Create a data.sql file and place it in the sql folder. When you have created that file copy the following into it: SQL Code use containerdb ; CREATE TABLE IF NOT EXISTS tbl_people ( ID INT ( 11 ) AUTO_INCREMENT , FNAME VARCHAR ( 20 ) NOT NULL , LNAME VARCHAR ( 30 ) NOT NULL , DOB DATE NOT NULL , PRIMARY KEY ( ID ) ) AUTO_INCREMENT = 1 ; INSERT INTO tbl_people ( FNAME , LNAME , DOB ) VALUES ( Bob , Taylor , 1954-04-01 ); INSERT INTO tbl_people ( FNAME , LNAME , DOB ) VALUES ( Lisa , Simpson , 2010-03-23 ); INSERT INTO tbl_people ( FNAME , LNAME , DOB ) VALUES ( Tim , Taylor , 1968-11-10 ); use containerdb ; SELECT * FROM tbl_people ; To able to add the code to the database, you will need to connect to the database first. To do that, make sure you have the extensions from above installed and do the following: Connect to the MySQL Database In the left bar expand the MySQL section and click on the plus button In the pop up at the top of the screen you will see an area when you can type in the host. If you are using Docker Toolbox type in 192.168.99.100 If you are using Docker native type in localhost Next type in the username to the database, in this case is user Next type in the password to the database, in this case is user1234 Next the port will be set to 3306 - leave this alone Next the path to the certificate will be blank - leave this alone The connection should now show up in the left panel of vscode. Once you have the database connection setup, open the data.sql that has the database code in it and right-click on an empty area in the code window and select Run MySQL Query If you have done all of this correctly, a side panel will open up and show you the following: ID FNAME LNAME DOB 1 Bob Taylor Thu Apr 01 1954 00:00:00 GMT+1300 (NZDT) 2 Lisa Simpson Tue Mar 23 2010 00:00:00 GMT+1300 (NZDT) 3 Tim Taylor Sun Nov 10 1968 00:00:00 GMT+1300 (NZDT) Updating the Model In the model we can create a new function that returns data from the database. We don't need any parameters for this, so it will just be a simple SELECT statement. First we need to establish the connection to the database, add the following code right below the class declaration private $db; public function __construct() { $this- db = new Database; } Next update your model with the following code by placing it below the title method: public function getAllPeople() { $this- db- query( SELECT * FROM tbl_people ); return $this- db- resultSet(); } The function above sends the query to the database and calls the resultSet() method, which is defined in the libraries/Database.php file The datatype this function returns will always be an array - even if it is only an array with a single index. Adding this function to the controller is exactly the same as what we did with the title, so go to the People Controller and update the index action to this: Updated index action public function index() { $title = $this- people- title(); $allPeople = $this- people- getAllPeople(); $data = [ title = $title, allPeople = $allPeople ]; return $this- view( people/view1 , $data); } Just see how it is the same and the only thing we have added is the variable that calls the getAllPeople() function and passed it into the $data array. Adding the data to the View Since the content of the $allPeople variable is an array, we need to loop through the data. So back in the view1.php file add the following code: Looping through the data echo ` br br `; //Only need this to create an empty line. $output = ; foreach($data[ allPeople ] as $people) { $output .= h2 .$people[ FNAME ]. .$people[ LNAME ]. /h2 ; } echo $output; Now when you refresh the page, you will see an database connection error. To fix this, change the value of the DBHOST in the .env file to mvcex01_db_1 The host of the database needs to be whatever your project is called in lower case followed by _db_1 . If you refresh your website now, you should see the following:","title":"Loading your database"},{"location":"php/mvc-framework/06-exercise-2/#loading_your_database","text":"Create a data.sql file and place it in the sql folder. When you have created that file copy the following into it: SQL Code use containerdb ; CREATE TABLE IF NOT EXISTS tbl_people ( ID INT ( 11 ) AUTO_INCREMENT , FNAME VARCHAR ( 20 ) NOT NULL , LNAME VARCHAR ( 30 ) NOT NULL , DOB DATE NOT NULL , PRIMARY KEY ( ID ) ) AUTO_INCREMENT = 1 ; INSERT INTO tbl_people ( FNAME , LNAME , DOB ) VALUES ( Bob , Taylor , 1954-04-01 ); INSERT INTO tbl_people ( FNAME , LNAME , DOB ) VALUES ( Lisa , Simpson , 2010-03-23 ); INSERT INTO tbl_people ( FNAME , LNAME , DOB ) VALUES ( Tim , Taylor , 1968-11-10 ); use containerdb ; SELECT * FROM tbl_people ; To able to add the code to the database, you will need to connect to the database first. To do that, make sure you have the extensions from above installed and do the following: Connect to the MySQL Database In the left bar expand the MySQL section and click on the plus button In the pop up at the top of the screen you will see an area when you can type in the host. If you are using Docker Toolbox type in 192.168.99.100 If you are using Docker native type in localhost Next type in the username to the database, in this case is user Next type in the password to the database, in this case is user1234 Next the port will be set to 3306 - leave this alone Next the path to the certificate will be blank - leave this alone The connection should now show up in the left panel of vscode. Once you have the database connection setup, open the data.sql that has the database code in it and right-click on an empty area in the code window and select Run MySQL Query If you have done all of this correctly, a side panel will open up and show you the following: ID FNAME LNAME DOB 1 Bob Taylor Thu Apr 01 1954 00:00:00 GMT+1300 (NZDT) 2 Lisa Simpson Tue Mar 23 2010 00:00:00 GMT+1300 (NZDT) 3 Tim Taylor Sun Nov 10 1968 00:00:00 GMT+1300 (NZDT)","title":"Loading your database"},{"location":"php/mvc-framework/06-exercise-2/#updating_the_model","text":"In the model we can create a new function that returns data from the database. We don't need any parameters for this, so it will just be a simple SELECT statement. First we need to establish the connection to the database, add the following code right below the class declaration private $db; public function __construct() { $this- db = new Database; } Next update your model with the following code by placing it below the title method: public function getAllPeople() { $this- db- query( SELECT * FROM tbl_people ); return $this- db- resultSet(); } The function above sends the query to the database and calls the resultSet() method, which is defined in the libraries/Database.php file The datatype this function returns will always be an array - even if it is only an array with a single index. Adding this function to the controller is exactly the same as what we did with the title, so go to the People Controller and update the index action to this: Updated index action public function index() { $title = $this- people- title(); $allPeople = $this- people- getAllPeople(); $data = [ title = $title, allPeople = $allPeople ]; return $this- view( people/view1 , $data); } Just see how it is the same and the only thing we have added is the variable that calls the getAllPeople() function and passed it into the $data array.","title":"Updating the Model"},{"location":"php/mvc-framework/06-exercise-2/#adding_the_data_to_the_view","text":"Since the content of the $allPeople variable is an array, we need to loop through the data. So back in the view1.php file add the following code: Looping through the data echo ` br br `; //Only need this to create an empty line. $output = ; foreach($data[ allPeople ] as $people) { $output .= h2 .$people[ FNAME ]. .$people[ LNAME ]. /h2 ; } echo $output; Now when you refresh the page, you will see an database connection error. To fix this, change the value of the DBHOST in the .env file to mvcex01_db_1 The host of the database needs to be whatever your project is called in lower case followed by _db_1 . If you refresh your website now, you should see the following:","title":"Adding the data to the View"},{"location":"web/01-introduction/","text":"Introduction Static Website This guide is to deploy a static website. i.e. A website without a dynamic backend. Static sites can include dynamic parts, but a good example of what this guide is not for is a website like WordPress where the content is delivered via a database. One of the main ways to deplopy a website used to be to use FTP (File Transfer Protocol) and was basically a drag 'n' drop approach to putting your website live on a server. If the image above you can see on the left side files that are locally on your machine and in the right panel you see the files that are on the web server. The big plus of this process by far is simplicity, but it comes with a few dangers: No file version tracking No test places, what is on the server is live for everyone to see So these days we use something called CI - Continuous Integration - and we use this to now deploy our websites, no matter what the complexity is. In this section we are going to look doing this with Parceljs and a service called Netlify . We are also going to be using Github and npm modules to achieve our goal, since we are using web frameworks like bootstrap.","title":"Introduction"},{"location":"web/01-introduction/#introduction","text":"Static Website This guide is to deploy a static website. i.e. A website without a dynamic backend. Static sites can include dynamic parts, but a good example of what this guide is not for is a website like WordPress where the content is delivered via a database. One of the main ways to deplopy a website used to be to use FTP (File Transfer Protocol) and was basically a drag 'n' drop approach to putting your website live on a server. If the image above you can see on the left side files that are locally on your machine and in the right panel you see the files that are on the web server. The big plus of this process by far is simplicity, but it comes with a few dangers: No file version tracking No test places, what is on the server is live for everyone to see So these days we use something called CI - Continuous Integration - and we use this to now deploy our websites, no matter what the complexity is. In this section we are going to look doing this with Parceljs and a service called Netlify . We are also going to be using Github and npm modules to achieve our goal, since we are using web frameworks like bootstrap.","title":"Introduction"},{"location":"web/02-setting-up-project/","text":"Project Setup In this example we are going to look at deploying a website using the bootstrap framework. Later in the exercises, you can test out this process yourself using bulma.io and tailwindcss The starter project can be found here . In this repository you can see there are 3 folders, each of them contain a single HTML file and make the same wesbite using 3 different UI frameworks. After cloning this repository, we are going to break it up into 3 new repositories, one for the example and two for the exercises. Clone the repository by copying the following command: git clone https://github.com/to-jk11/framework-answer-model After the clone is completed, copy the bootstrap folder and place it at the same level as the framework-answer-model folder. For example, if you cloned the framework-answer-model onto the Desktop, then place the bootstrap there as well. For now - until the exercises - you can ignore the framework-answer-model folder, but don't delete it. Running the bootstrap project. If you look at the code in the bootstrap folder, you can see the links to the framework (css and javascript) are absolute and they are linking to an external CSS. When we put our website in production, we want it to always work and show the right frameworks - so we don't want to rely on an external resource for this. In the bootstrap folder we need to create a git repository, so navigate into the folder and type in: git init Next we need to create a .gitignore file and need to fill it with the following lines: .DS_Store node_modules/ These lines stop us from including the node_modules folder and the indexing file that is created on a machine running macOS. Since you are never sure on what machine your project will be running, it is good practice to add the .DS_Store - even if you don't use a mac Next we need to create a package.json file. Previous Knowledge Previously we looked at how to add NPM packages to our project, so I am not going to explain the pro's and con's in much detail. I will just explain the steps on what to do. To be able to add your frameworks locally to your project, we will use something called NPM (Node Package Modules). To save the package we use with our project we need to create a package.json file. Open the bootstrap folder in vscode and open the integrated terminal and type in: npm init -y The above command will create a package.json file for you and it will allow us to save a list of our web dependencies which are used to download our frameworks. First let's add the frameworks required for making a bootstrap website - type the following into the terminal: npm i bootstrap popper.js jquery You should end up with an error that contains the following line: npm ERR! Refusing to install package with name \"bootstrap\" under a package npm ERR! also called \"bootstrap\". Did you name your project the same npm ERR! as the dependency you're installing? This is because your project name at the top of the package.json file is bootstrap and npm cannot install a package with the same name. So change the name of the project to bootstrap_ and run the command again and you shouldn't have any issues. In the index.html file you can now change the links relevant to the frameworks to the npm packages. For the CSS this will be: link rel= stylesheet href= /node_modules/bootstrap/dist/css/bootstrap.min.css For the Script tags just above the /body this will be: script src= /node_modules/jquery/dist/jquery.slim.min.js /script script src= /node_modules/popper.js/dist/umd/popper.min.js /script script src= /node_modules/bootstrap/dist/js/bootstrap.min.js /script Now using Live server you are able to run the project and see that the website looks the same, but this time the framework is local to our project. Live-Server Live server can be installed in a couple of ways: Using vscode, we can install the extension by typing the following into the terminal: code --install-extension ritwickdey.liveserver To run the live-server extension, use the \"go live\" button at the bottom or find it in the quick menu. The website will open on http://localhost:5500 using your default browser. Using npm, we can install a local live-server by typing the following into the terminal: npm i -g live-server To run the live server using npm do this: live-server --no-browser . No browser will open by default, but you can access the page from http://localhost:8080 using any browser. Now we have our project running with the frameworks locally to our project, next we are going to look at the first step of deployment. It would be a wise move to make a commit now, since we are about to push our code up to GitHub.","title":"Project Setup"},{"location":"web/02-setting-up-project/#project_setup","text":"In this example we are going to look at deploying a website using the bootstrap framework. Later in the exercises, you can test out this process yourself using bulma.io and tailwindcss The starter project can be found here . In this repository you can see there are 3 folders, each of them contain a single HTML file and make the same wesbite using 3 different UI frameworks. After cloning this repository, we are going to break it up into 3 new repositories, one for the example and two for the exercises. Clone the repository by copying the following command: git clone https://github.com/to-jk11/framework-answer-model After the clone is completed, copy the bootstrap folder and place it at the same level as the framework-answer-model folder. For example, if you cloned the framework-answer-model onto the Desktop, then place the bootstrap there as well. For now - until the exercises - you can ignore the framework-answer-model folder, but don't delete it.","title":"Project Setup"},{"location":"web/02-setting-up-project/#running_the_bootstrap_project","text":"If you look at the code in the bootstrap folder, you can see the links to the framework (css and javascript) are absolute and they are linking to an external CSS. When we put our website in production, we want it to always work and show the right frameworks - so we don't want to rely on an external resource for this. In the bootstrap folder we need to create a git repository, so navigate into the folder and type in: git init Next we need to create a .gitignore file and need to fill it with the following lines: .DS_Store node_modules/ These lines stop us from including the node_modules folder and the indexing file that is created on a machine running macOS. Since you are never sure on what machine your project will be running, it is good practice to add the .DS_Store - even if you don't use a mac Next we need to create a package.json file. Previous Knowledge Previously we looked at how to add NPM packages to our project, so I am not going to explain the pro's and con's in much detail. I will just explain the steps on what to do. To be able to add your frameworks locally to your project, we will use something called NPM (Node Package Modules). To save the package we use with our project we need to create a package.json file. Open the bootstrap folder in vscode and open the integrated terminal and type in: npm init -y The above command will create a package.json file for you and it will allow us to save a list of our web dependencies which are used to download our frameworks. First let's add the frameworks required for making a bootstrap website - type the following into the terminal: npm i bootstrap popper.js jquery You should end up with an error that contains the following line: npm ERR! Refusing to install package with name \"bootstrap\" under a package npm ERR! also called \"bootstrap\". Did you name your project the same npm ERR! as the dependency you're installing? This is because your project name at the top of the package.json file is bootstrap and npm cannot install a package with the same name. So change the name of the project to bootstrap_ and run the command again and you shouldn't have any issues. In the index.html file you can now change the links relevant to the frameworks to the npm packages. For the CSS this will be: link rel= stylesheet href= /node_modules/bootstrap/dist/css/bootstrap.min.css For the Script tags just above the /body this will be: script src= /node_modules/jquery/dist/jquery.slim.min.js /script script src= /node_modules/popper.js/dist/umd/popper.min.js /script script src= /node_modules/bootstrap/dist/js/bootstrap.min.js /script Now using Live server you are able to run the project and see that the website looks the same, but this time the framework is local to our project. Live-Server Live server can be installed in a couple of ways: Using vscode, we can install the extension by typing the following into the terminal: code --install-extension ritwickdey.liveserver To run the live-server extension, use the \"go live\" button at the bottom or find it in the quick menu. The website will open on http://localhost:5500 using your default browser. Using npm, we can install a local live-server by typing the following into the terminal: npm i -g live-server To run the live server using npm do this: live-server --no-browser . No browser will open by default, but you can access the page from http://localhost:8080 using any browser. Now we have our project running with the frameworks locally to our project, next we are going to look at the first step of deployment. It would be a wise move to make a commit now, since we are about to push our code up to GitHub.","title":"Running the bootstrap project."},{"location":"web/03-push-and-deploy/","text":"Pushing our code to GitHub In order for CI to work, we need a repository - so let's push our code up to GitHub. Go to http://github.com/new page and create a new repository - I have called it pg-netlify, but call it whatever you want. In your repository link the remote repository to your local project by typing the following into the terminal: git remote add origin https://github.com/ username /pg-netlify Push your code to GitHub: git add . git commit -m Initial Commit git push origin master You may be prompted to type in your credentials, so do so if required. Once the code has been pushed, you should be able to see the files after refreshing the GitHub page. Setting up Netlify Netlify is a service that allows to host our website for free (they use a freemium business model, which is nice in our case). Go to Netlify.com and sign up for an account - you can use your GitHub account for a SSO option. Once it is setup, you can click the \"New site from GitHub\" button, which is on the right and a teal colour. You then see the following screen, where you can click on the GitHub button: A pop up screen will come up (check if your browser is blocking it) and go through the motions of authenticating your GitHub account and give it access. After you have completed this, you should be able to search for your repository. Once you have found it, select it and you should see the following screen: Just click the \"Deploy Site\" button - if the future you will add the Build Command, but for now let's ignore this. You site will be deployed and after a few seconds you should be able to preview your site. If all goes well, the console in the browser should say \"Site is Live\" Click on the preview button towards the top and you should see the website, but you may notice something is missing.... This is what we are going to fix on the next page:","title":"Pushing our code to GitHub"},{"location":"web/03-push-and-deploy/#pushing_our_code_to_github","text":"In order for CI to work, we need a repository - so let's push our code up to GitHub. Go to http://github.com/new page and create a new repository - I have called it pg-netlify, but call it whatever you want. In your repository link the remote repository to your local project by typing the following into the terminal: git remote add origin https://github.com/ username /pg-netlify Push your code to GitHub: git add . git commit -m Initial Commit git push origin master You may be prompted to type in your credentials, so do so if required. Once the code has been pushed, you should be able to see the files after refreshing the GitHub page.","title":"Pushing our code to GitHub"},{"location":"web/03-push-and-deploy/#setting_up_netlify","text":"Netlify is a service that allows to host our website for free (they use a freemium business model, which is nice in our case). Go to Netlify.com and sign up for an account - you can use your GitHub account for a SSO option. Once it is setup, you can click the \"New site from GitHub\" button, which is on the right and a teal colour. You then see the following screen, where you can click on the GitHub button: A pop up screen will come up (check if your browser is blocking it) and go through the motions of authenticating your GitHub account and give it access. After you have completed this, you should be able to search for your repository. Once you have found it, select it and you should see the following screen: Just click the \"Deploy Site\" button - if the future you will add the Build Command, but for now let's ignore this. You site will be deployed and after a few seconds you should be able to preview your site. If all goes well, the console in the browser should say \"Site is Live\" Click on the preview button towards the top and you should see the website, but you may notice something is missing.... This is what we are going to fix on the next page:","title":"Setting up Netlify"},{"location":"web/04-parcel/","text":"Using parceljs The problem we are currently having is that we do not see any of our styles and our scripts do not work. When our website is hosted on a shared hosting server, we do not have access to the node_modules folder - so we need to find a work around. Parceljs is a \"Blazing fast, zero configuration web application bundler\" and it creates a production version of our website without using the node_modules folder. To use parceljs we need to add it to our package.json file. npm i parcel-bundler --save-dev You will notice that your package.json will now contain the following code: dependencies : { bootstrap : ^4.3.1 , jquery : ^3.4.1 , popper.js : ^1.15.0 } , devDependencies : { parcel-bundler : ^1.12.3 } The parcel-bundler is listed under devDependencies because it is only required while our website is under development, where as the frameworks are used to support our website at all times. Next we need to make another change to our package.json file: Change: scripts : { test : echo \\ Error: no test specified\\ exit 1 } , into this: scripts : { test : echo \\ Error: no test specified\\ exit 1 , dev : parcel index.html , build : parcel build index.html } , Save the file and now you can run the command: npm run dev This will package up the website and run it on a local server available from http://localhost:1234 . Before we make a commit, we want to update our .gitignore file to the following: .DS_Store node_modules/ dist/ .cache/ The new entries are part of parceljs and are generated code that will be done on the remote server. Make a commit, but do not push it up to GitHub yet. Updating Netlify Back on the Netlify we now need to make a few changes to our configuration: Go to the app page and select the project you created earlier. Click on \"Deploys\" in the top menu Click on the \"Deploy Settings\" button on the next screen Click in \"Edit settings\" button in the Build settings section In the \"Build settings\" field add npm run build In the \"Publish directory\" field add /dist Click on the Save button. Now you can push up your latest commit - the following will happen: Your project is pushed up to GitHub Netlify recognises that there is a new commit and pulls the information Netlify starts buidling your site by using the build command you previously entered Your site should be live in about a minute on the same link as before, but this time the styles and scripts will work. Congratualtions - you have published your website and made your first Continous Integration ! REMEMBER Each time you now push to master, netlify will kick in and update the url What now? At this stage you are using a sub-domain url based on the netlify domain, look through the options on how you can add your own domain if you have one. A nice things Netlify does for you is give you HTTPS for free!","title":"Using parceljs"},{"location":"web/04-parcel/#using_parceljs","text":"The problem we are currently having is that we do not see any of our styles and our scripts do not work. When our website is hosted on a shared hosting server, we do not have access to the node_modules folder - so we need to find a work around. Parceljs is a \"Blazing fast, zero configuration web application bundler\" and it creates a production version of our website without using the node_modules folder. To use parceljs we need to add it to our package.json file. npm i parcel-bundler --save-dev You will notice that your package.json will now contain the following code: dependencies : { bootstrap : ^4.3.1 , jquery : ^3.4.1 , popper.js : ^1.15.0 } , devDependencies : { parcel-bundler : ^1.12.3 } The parcel-bundler is listed under devDependencies because it is only required while our website is under development, where as the frameworks are used to support our website at all times. Next we need to make another change to our package.json file: Change: scripts : { test : echo \\ Error: no test specified\\ exit 1 } , into this: scripts : { test : echo \\ Error: no test specified\\ exit 1 , dev : parcel index.html , build : parcel build index.html } , Save the file and now you can run the command: npm run dev This will package up the website and run it on a local server available from http://localhost:1234 . Before we make a commit, we want to update our .gitignore file to the following: .DS_Store node_modules/ dist/ .cache/ The new entries are part of parceljs and are generated code that will be done on the remote server. Make a commit, but do not push it up to GitHub yet.","title":"Using parceljs"},{"location":"web/04-parcel/#updating_netlify","text":"Back on the Netlify we now need to make a few changes to our configuration: Go to the app page and select the project you created earlier. Click on \"Deploys\" in the top menu Click on the \"Deploy Settings\" button on the next screen Click in \"Edit settings\" button in the Build settings section In the \"Build settings\" field add npm run build In the \"Publish directory\" field add /dist Click on the Save button. Now you can push up your latest commit - the following will happen: Your project is pushed up to GitHub Netlify recognises that there is a new commit and pulls the information Netlify starts buidling your site by using the build command you previously entered Your site should be live in about a minute on the same link as before, but this time the styles and scripts will work. Congratualtions - you have published your website and made your first Continous Integration ! REMEMBER Each time you now push to master, netlify will kick in and update the url What now? At this stage you are using a sub-domain url based on the netlify domain, look through the options on how you can add your own domain if you have one. A nice things Netlify does for you is give you HTTPS for free!","title":"Updating Netlify"},{"location":"web/05-exercises/","text":"Exercises Right so now that the bootstrap site is live - there are 2 more to do: bulma.io tailwindcss Follow the same steps and show them in the next class.","title":"Exercises"},{"location":"web/05-exercises/#exercises","text":"Right so now that the bootstrap site is live - there are 2 more to do: bulma.io tailwindcss Follow the same steps and show them in the next class.","title":"Exercises"}]}